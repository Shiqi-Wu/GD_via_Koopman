{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa009e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 22px;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 22px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb1e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd822cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2553fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 11:07:37.896146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 11:07:38.023535: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-28 11:07:38.642398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-28 11:07:38.642456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-28 11:07:38.642462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-28 11:07:39.455370: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-28 11:07:39.455448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: deneb\n",
      "2023-03-28 11:07:39.455465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: deneb\n",
      "2023-03-28 11:07:39.455634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.103.1\n",
      "2023-03-28 11:07:39.455691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.103.1\n",
      "2023-03-28 11:07:39.455704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.103.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    # logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    # print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54275ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "node_num = 16\n",
    "training_id = 0\n",
    "weight = np.load('learn_output/weight_%d_%d.npy' % (node_num, training_id), allow_pickle=True)\n",
    "x_train = weight[:-1,:]\n",
    "y_train = weight[1:,:]\n",
    "for training_id in range(1, 10):\n",
    "    weight = np.load('learn_output/weight_%d_%d.npy' % (node_num, training_id), allow_pickle=True)\n",
    "    x_train = np.concatenate((x_train, weight[:-1,:]), axis = 0)\n",
    "    y_train = np.concatenate((y_train, weight[1:,:]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa3573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 466)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c80fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.layers import Input, Add, Multiply, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class DicNN(Layer):\n",
    "    \"\"\"\n",
    "    Trainable disctionries\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_input, layer_sizes=[64, 64], n_psi_train=32, **kwargs):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            layer_sizes (list, optional): Number of unit of hidden layer, activation = 'tanh'. Defaults to [64, 64].\n",
    "            n_psi_train (int, optional): Number of unit of output layer. Defaults to 22.\n",
    "        \"\"\"\n",
    "        super(DicNN, self).__init__(**kwargs)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_layer = Dense(self.layer_sizes[0], name='Dic_input', use_bias=False)\n",
    "        self.hidden_layers = [Dense(layer_sizes[i], activation='tanh', name='Dic_hidden_%d'%i) for i in range(len(layer_sizes))]        \n",
    "        self.output_layer = Dense(n_psi_train, name='Dic_output')\n",
    "        self.n_psi_train = n_psi_train\n",
    "        self.inv_input_layer = Dense(self.layer_sizes[-1], name = 'Dic_input_inv', use_bias=False)\n",
    "        self.inv_hidden_layers = [Dense(layer_sizes[-(i+1)], activation='tanh', name='Dic_hidden_%d_inv'%i) for i in range(len(layer_sizes))]\n",
    "        self.inv_output_layer = Dense(n_input, name = 'Dic_output_inv')\n",
    "        self.n_input = n_input\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        psi_x_train = self.input_layer(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            psi_x_train = psi_x_train + layer(psi_x_train)\n",
    "        outputs = self.output_layer(psi_x_train)\n",
    "        return outputs\n",
    "    \n",
    "    def inv_call(self, inputs):\n",
    "        x_inv = self.inv_input_layer(inputs)\n",
    "        for layer in self.inv_hidden_layers:\n",
    "            x_inv = x_inv + layer(x_inv)\n",
    "        outputs = self.inv_output_layer(x_inv)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(DicNN, self).get_config()\n",
    "        config.update({\n",
    "            'layer_sizes': self.layer_sizes,\n",
    "            'n_psi_train': self.n_psi_train\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad6fb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 11:07:39.813703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dic = DicNN(n_input = np.shape(x_train)[1], layer_sizes=[128, 128])\n",
    "inputs_x = Input((np.shape(x_train)[1],))\n",
    "model_psi = Model(inputs = inputs_x, outputs = dic.call(inputs_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd42caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eigenloss(matrix, static_num, epsilon):\n",
    "    eigvalues = tf.linalg.eigvals(matrix)\n",
    "    static_values, dynamic_values = eigvalues[:static_num], eigvalues[static_num:]\n",
    "    E1 = tf.reduce_sum(tf.abs(static_values - 1)**2)\n",
    "    dynamic_values = tf.where(tf.abs(dynamic_values) < epsilon, tf.zeros_like(dynamic_values), dynamic_values)\n",
    "    E2 = tf.reduce_sum(tf.abs(dynamic_values)**2)\n",
    "    return E1, E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34eb06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_x = Input((np.shape(x_train)[1],))\n",
    "inputs_y = Input((np.shape(y_train)[1],))\n",
    "psi_x = model_psi(inputs_x)\n",
    "psi_y = model_psi(inputs_y)\n",
    "k_layer = Dense(units = dic.n_psi_train, use_bias=False, name = 'k_layer')\n",
    "outputs_x = k_layer(psi_x)\n",
    "outputs = outputs_x - psi_y\n",
    "model_koopman = Model(inputs = [inputs_x, inputs_y], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7db06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_x = Input((np.shape(x_train)[1],))\n",
    "psi_x = model_psi(inputs_x)\n",
    "inputs_kpsi = Input((dic.n_psi_train,))\n",
    "model_inv_psi = Model(inputs = inputs_kpsi, outputs = dic.inv_call(inputs_kpsi))\n",
    "model_auto = Model(inputs = inputs_x, outputs = model_inv_psi(psi_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a660f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = tf.keras.layers.Input(shape=(x_train.shape[1],))\n",
    "input_y = tf.keras.layers.Input(shape=(y_train.shape[1],))\n",
    "output_auto = model_auto(input_x)\n",
    "output_koopman = model_koopman([input_x, input_y])\n",
    "combined_model = tf.keras.models.Model(inputs=[input_x, input_y], outputs=[output_auto, output_koopman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfc825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(alpha, beta, gamma, epsilon, static_num, model_auto, model_koopman):\n",
    "    def loss(y_true, y_pred):\n",
    "        \n",
    "        # Compute the maximum eigenvalue of the k_layer\n",
    "        k_layer = model_koopman.get_layer('k_layer')\n",
    "        matrix = k_layer.trainable_variables[0]\n",
    "        E1, E2 = eigenloss(matrix, static_num, epsilon)\n",
    "        \n",
    "        # Compute the Koopman operator loss\n",
    "        koopman_loss = tf.keras.losses.MSE(y_pred[1], y_true[1])\n",
    "    \n",
    "        # Compute the reconstruction loss\n",
    "        recon_loss = tf.keras.losses.MSE(y_pred[0], y_true[0])\n",
    "        \n",
    "        # Compute the final loss\n",
    "        return alpha * koopman_loss + beta * recon_loss + gamma[0] * E1 + gamma[1] * E2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "316d03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 500\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "# gamma = [0.05,0.05]\n",
    "gamma = [0,0]\n",
    "epsilon = 0.8\n",
    "static_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5650db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(optimizer='adam', loss=custom_loss(alpha, beta, gamma, epsilon, static_num, model_auto, model_koopman))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ded1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "y_train_scaled = scaler.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44003074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 2s 8ms/step - loss: 7.3063 - model_3_loss: 1.7422 - model_1_loss: 5.5641\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.8239 - model_3_loss: 1.1026 - model_1_loss: 2.7213\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9937 - model_3_loss: 0.8243 - model_1_loss: 1.1693\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9523 - model_3_loss: 0.9533 - model_1_loss: 0.9990\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5256 - model_3_loss: 0.7088 - model_1_loss: 0.8169\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3535 - model_3_loss: 0.7139 - model_1_loss: 0.6397\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0760 - model_3_loss: 0.6010 - model_1_loss: 0.4750\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0783 - model_3_loss: 0.5332 - model_1_loss: 0.5451\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9544 - model_3_loss: 0.4006 - model_1_loss: 0.5538\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7755 - model_3_loss: 0.3521 - model_1_loss: 0.4233\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7507 - model_3_loss: 0.3747 - model_1_loss: 0.3761\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9119 - model_3_loss: 0.3743 - model_1_loss: 0.5376\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6354 - model_3_loss: 0.3054 - model_1_loss: 0.3300\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6667 - model_3_loss: 0.2632 - model_1_loss: 0.4035\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4943 - model_3_loss: 0.2308 - model_1_loss: 0.2634\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3513 - model_3_loss: 0.1965 - model_1_loss: 0.1548\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3194 - model_3_loss: 0.1608 - model_1_loss: 0.1587\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3236 - model_3_loss: 0.1578 - model_1_loss: 0.1659\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3284 - model_3_loss: 0.1447 - model_1_loss: 0.1837\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3355 - model_3_loss: 0.1507 - model_1_loss: 0.1848\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3922 - model_3_loss: 0.1741 - model_1_loss: 0.2181\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3803 - model_3_loss: 0.1587 - model_1_loss: 0.2216\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3223 - model_3_loss: 0.1534 - model_1_loss: 0.1689\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2969 - model_3_loss: 0.1309 - model_1_loss: 0.1660\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3515 - model_3_loss: 0.1619 - model_1_loss: 0.1897\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3100 - model_3_loss: 0.1456 - model_1_loss: 0.1644\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3132 - model_3_loss: 0.1513 - model_1_loss: 0.1618\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3350 - model_3_loss: 0.1408 - model_1_loss: 0.1942\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2471 - model_3_loss: 0.1016 - model_1_loss: 0.1455\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2134 - model_3_loss: 0.1092 - model_1_loss: 0.1042\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1783 - model_3_loss: 0.0883 - model_1_loss: 0.0900\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2448 - model_3_loss: 0.1081 - model_1_loss: 0.1367\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2421 - model_3_loss: 0.1355 - model_1_loss: 0.1066\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2911 - model_3_loss: 0.1290 - model_1_loss: 0.1621\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2687 - model_3_loss: 0.1199 - model_1_loss: 0.1488\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2181 - model_3_loss: 0.1069 - model_1_loss: 0.1112\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1873 - model_3_loss: 0.1058 - model_1_loss: 0.0815\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2244 - model_3_loss: 0.1212 - model_1_loss: 0.1031\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2042 - model_3_loss: 0.1018 - model_1_loss: 0.1024\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1910 - model_3_loss: 0.0881 - model_1_loss: 0.1029\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1821 - model_3_loss: 0.0853 - model_1_loss: 0.0969\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2001 - model_3_loss: 0.1138 - model_1_loss: 0.0863\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1729 - model_3_loss: 0.1006 - model_1_loss: 0.0723\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1920 - model_3_loss: 0.1014 - model_1_loss: 0.0906\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1803 - model_3_loss: 0.0946 - model_1_loss: 0.0857\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2050 - model_3_loss: 0.1129 - model_1_loss: 0.0921\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2540 - model_3_loss: 0.1094 - model_1_loss: 0.1446\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3363 - model_3_loss: 0.1185 - model_1_loss: 0.2179\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3594 - model_3_loss: 0.0947 - model_1_loss: 0.2647\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3497 - model_3_loss: 0.0947 - model_1_loss: 0.2550\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4543 - model_3_loss: 0.1047 - model_1_loss: 0.3497\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3529 - model_3_loss: 0.1022 - model_1_loss: 0.2507\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3325 - model_3_loss: 0.1395 - model_1_loss: 0.1929\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1823 - model_3_loss: 0.0895 - model_1_loss: 0.0929\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2212 - model_3_loss: 0.1096 - model_1_loss: 0.1116\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2283 - model_3_loss: 0.0924 - model_1_loss: 0.1360\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1660 - model_3_loss: 0.0880 - model_1_loss: 0.0781\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1889 - model_3_loss: 0.0869 - model_1_loss: 0.1020\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1976 - model_3_loss: 0.0972 - model_1_loss: 0.1004\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2316 - model_3_loss: 0.1076 - model_1_loss: 0.1240\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1948 - model_3_loss: 0.0829 - model_1_loss: 0.1119\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1885 - model_3_loss: 0.0905 - model_1_loss: 0.0980\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2116 - model_3_loss: 0.0823 - model_1_loss: 0.1292\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1316 - model_3_loss: 0.0566 - model_1_loss: 0.0750\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0988 - model_3_loss: 0.0518 - model_1_loss: 0.0470\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1623 - model_3_loss: 0.1073 - model_1_loss: 0.0550\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1135 - model_3_loss: 0.0722 - model_1_loss: 0.0412\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1511 - model_3_loss: 0.0780 - model_1_loss: 0.0731\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1495 - model_3_loss: 0.0824 - model_1_loss: 0.0672\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1290 - model_3_loss: 0.0708 - model_1_loss: 0.0583\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1271 - model_3_loss: 0.0655 - model_1_loss: 0.0616\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1016 - model_3_loss: 0.0461 - model_1_loss: 0.0555\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1011 - model_3_loss: 0.0614 - model_1_loss: 0.0396\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0856 - model_3_loss: 0.0526 - model_1_loss: 0.0330\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1002 - model_3_loss: 0.0528 - model_1_loss: 0.0474\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1107 - model_3_loss: 0.0610 - model_1_loss: 0.0497\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1158 - model_3_loss: 0.0540 - model_1_loss: 0.0617\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1108 - model_3_loss: 0.0526 - model_1_loss: 0.0582\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0897 - model_3_loss: 0.0513 - model_1_loss: 0.0384\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0742 - model_3_loss: 0.0429 - model_1_loss: 0.0313\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0709 - model_3_loss: 0.0448 - model_1_loss: 0.0261\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0842 - model_3_loss: 0.0519 - model_1_loss: 0.0323\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0895 - model_3_loss: 0.0519 - model_1_loss: 0.0375\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0928 - model_3_loss: 0.0496 - model_1_loss: 0.0432\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0787 - model_3_loss: 0.0469 - model_1_loss: 0.0319\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0986 - model_3_loss: 0.0513 - model_1_loss: 0.0473\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0807 - model_3_loss: 0.0500 - model_1_loss: 0.0307\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0868 - model_3_loss: 0.0498 - model_1_loss: 0.0370\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1134 - model_3_loss: 0.0536 - model_1_loss: 0.0598\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0815 - model_3_loss: 0.0533 - model_1_loss: 0.0283\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0833 - model_3_loss: 0.0572 - model_1_loss: 0.0261\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0850 - model_3_loss: 0.0524 - model_1_loss: 0.0327\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0680 - model_3_loss: 0.0403 - model_1_loss: 0.0278\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0591 - model_3_loss: 0.0367 - model_1_loss: 0.0224\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0884 - model_3_loss: 0.0373 - model_1_loss: 0.0510\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1109 - model_3_loss: 0.0512 - model_1_loss: 0.0598\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0932 - model_3_loss: 0.0480 - model_1_loss: 0.0452\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1078 - model_3_loss: 0.0535 - model_1_loss: 0.0543\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1053 - model_3_loss: 0.0615 - model_1_loss: 0.0438\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0771 - model_3_loss: 0.0417 - model_1_loss: 0.0354\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1442 - model_3_loss: 0.0628 - model_1_loss: 0.0814\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1022 - model_3_loss: 0.0497 - model_1_loss: 0.0525\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0795 - model_3_loss: 0.0389 - model_1_loss: 0.0406\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1399 - model_3_loss: 0.0590 - model_1_loss: 0.0809\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1782 - model_3_loss: 0.0668 - model_1_loss: 0.1114\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2006 - model_3_loss: 0.0591 - model_1_loss: 0.1415\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1218 - model_3_loss: 0.0525 - model_1_loss: 0.0694\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0948 - model_3_loss: 0.0518 - model_1_loss: 0.0430\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1266 - model_3_loss: 0.0549 - model_1_loss: 0.0717\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1041 - model_3_loss: 0.0574 - model_1_loss: 0.0467\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0846 - model_3_loss: 0.0478 - model_1_loss: 0.0368\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0723 - model_3_loss: 0.0423 - model_1_loss: 0.0300\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0637 - model_3_loss: 0.0377 - model_1_loss: 0.0259\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0836 - model_3_loss: 0.0445 - model_1_loss: 0.0391\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0799 - model_3_loss: 0.0429 - model_1_loss: 0.0370\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0697 - model_3_loss: 0.0358 - model_1_loss: 0.0338\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0601 - model_3_loss: 0.0343 - model_1_loss: 0.0258\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0598 - model_3_loss: 0.0363 - model_1_loss: 0.0235\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0665 - model_3_loss: 0.0422 - model_1_loss: 0.0244\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0659 - model_3_loss: 0.0364 - model_1_loss: 0.0295\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0682 - model_3_loss: 0.0422 - model_1_loss: 0.0260\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0858 - model_3_loss: 0.0543 - model_1_loss: 0.0315\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0666 - model_3_loss: 0.0383 - model_1_loss: 0.0283\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0598 - model_3_loss: 0.0380 - model_1_loss: 0.0218\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0592 - model_3_loss: 0.0318 - model_1_loss: 0.0275\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0712 - model_3_loss: 0.0334 - model_1_loss: 0.0377\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0744 - model_3_loss: 0.0390 - model_1_loss: 0.0354\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0592 - model_3_loss: 0.0413 - model_1_loss: 0.0179\n",
      "Epoch 129/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0756 - model_3_loss: 0.0424 - model_1_loss: 0.0331\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0550 - model_3_loss: 0.0317 - model_1_loss: 0.0232\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0489 - model_3_loss: 0.0286 - model_1_loss: 0.0203\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0438 - model_3_loss: 0.0299 - model_1_loss: 0.0139\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0427 - model_3_loss: 0.0312 - model_1_loss: 0.0115\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0438 - model_3_loss: 0.0286 - model_1_loss: 0.0152\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0528 - model_3_loss: 0.0407 - model_1_loss: 0.0121\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0656 - model_3_loss: 0.0419 - model_1_loss: 0.0237\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0396 - model_3_loss: 0.0277 - model_1_loss: 0.0120\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0500 - model_3_loss: 0.0320 - model_1_loss: 0.0180\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0616 - model_3_loss: 0.0398 - model_1_loss: 0.0217\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0563 - model_3_loss: 0.0323 - model_1_loss: 0.0240\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0565 - model_3_loss: 0.0286 - model_1_loss: 0.0279\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0717 - model_3_loss: 0.0278 - model_1_loss: 0.0440\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1078 - model_3_loss: 0.0496 - model_1_loss: 0.0582\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0787 - model_3_loss: 0.0389 - model_1_loss: 0.0398\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0634 - model_3_loss: 0.0352 - model_1_loss: 0.0282\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0601 - model_3_loss: 0.0393 - model_1_loss: 0.0208\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0463 - model_3_loss: 0.0265 - model_1_loss: 0.0198\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0560 - model_3_loss: 0.0331 - model_1_loss: 0.0229\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0614 - model_3_loss: 0.0423 - model_1_loss: 0.0191\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0702 - model_3_loss: 0.0477 - model_1_loss: 0.0226\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1095 - model_3_loss: 0.0487 - model_1_loss: 0.0607\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0873 - model_3_loss: 0.0450 - model_1_loss: 0.0424\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0546 - model_3_loss: 0.0335 - model_1_loss: 0.0211\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0467 - model_3_loss: 0.0279 - model_1_loss: 0.0189\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0727 - model_3_loss: 0.0348 - model_1_loss: 0.0379\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0642 - model_3_loss: 0.0319 - model_1_loss: 0.0323\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0696 - model_3_loss: 0.0343 - model_1_loss: 0.0354\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0665 - model_3_loss: 0.0354 - model_1_loss: 0.0311\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0774 - model_3_loss: 0.0382 - model_1_loss: 0.0392\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0652 - model_3_loss: 0.0297 - model_1_loss: 0.0356\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0750 - model_3_loss: 0.0388 - model_1_loss: 0.0362\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0573 - model_3_loss: 0.0282 - model_1_loss: 0.0291\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0520 - model_3_loss: 0.0304 - model_1_loss: 0.0217\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0499 - model_3_loss: 0.0267 - model_1_loss: 0.0232\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0610 - model_3_loss: 0.0351 - model_1_loss: 0.0259\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0588 - model_3_loss: 0.0357 - model_1_loss: 0.0230\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0549 - model_3_loss: 0.0368 - model_1_loss: 0.0181\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0559 - model_3_loss: 0.0347 - model_1_loss: 0.0212\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0479 - model_3_loss: 0.0273 - model_1_loss: 0.0206\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0455 - model_3_loss: 0.0287 - model_1_loss: 0.0168\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0414 - model_3_loss: 0.0298 - model_1_loss: 0.0116\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0355 - model_3_loss: 0.0213 - model_1_loss: 0.0142\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0414 - model_3_loss: 0.0252 - model_1_loss: 0.0162\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0404 - model_3_loss: 0.0236 - model_1_loss: 0.0167\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0410 - model_3_loss: 0.0245 - model_1_loss: 0.0165\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0410 - model_3_loss: 0.0246 - model_1_loss: 0.0164\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0379 - model_3_loss: 0.0230 - model_1_loss: 0.0149\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0349 - model_3_loss: 0.0245 - model_1_loss: 0.0104\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0319 - model_3_loss: 0.0205 - model_1_loss: 0.0114\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0374 - model_3_loss: 0.0274 - model_1_loss: 0.0100\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0348 - model_3_loss: 0.0239 - model_1_loss: 0.0109\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0421 - model_3_loss: 0.0258 - model_1_loss: 0.0164\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0370 - model_3_loss: 0.0250 - model_1_loss: 0.0120\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0348 - model_3_loss: 0.0256 - model_1_loss: 0.0092\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0355 - model_3_loss: 0.0290 - model_1_loss: 0.0065\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0289 - model_3_loss: 0.0209 - model_1_loss: 0.0080\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0440 - model_3_loss: 0.0305 - model_1_loss: 0.0135\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0431 - model_3_loss: 0.0303 - model_1_loss: 0.0128\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0387 - model_3_loss: 0.0294 - model_1_loss: 0.0093\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0389 - model_3_loss: 0.0282 - model_1_loss: 0.0107\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0456 - model_3_loss: 0.0295 - model_1_loss: 0.0161\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0451 - model_3_loss: 0.0285 - model_1_loss: 0.0167\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0591 - model_3_loss: 0.0322 - model_1_loss: 0.0269\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0651 - model_3_loss: 0.0417 - model_1_loss: 0.0234\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0559 - model_3_loss: 0.0341 - model_1_loss: 0.0218\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0384 - model_3_loss: 0.0216 - model_1_loss: 0.0168\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0534 - model_3_loss: 0.0256 - model_1_loss: 0.0277\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0607 - model_3_loss: 0.0365 - model_1_loss: 0.0243\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0618 - model_3_loss: 0.0309 - model_1_loss: 0.0309\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0775 - model_3_loss: 0.0450 - model_1_loss: 0.0325\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0793 - model_3_loss: 0.0419 - model_1_loss: 0.0374\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0576 - model_3_loss: 0.0393 - model_1_loss: 0.0183\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0512 - model_3_loss: 0.0335 - model_1_loss: 0.0178\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0432 - model_3_loss: 0.0309 - model_1_loss: 0.0123\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0463 - model_3_loss: 0.0331 - model_1_loss: 0.0132\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0506 - model_3_loss: 0.0359 - model_1_loss: 0.0148\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0481 - model_3_loss: 0.0324 - model_1_loss: 0.0157\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0551 - model_3_loss: 0.0320 - model_1_loss: 0.0231\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0424 - model_3_loss: 0.0213 - model_1_loss: 0.0211\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0605 - model_3_loss: 0.0346 - model_1_loss: 0.0259\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0503 - model_3_loss: 0.0382 - model_1_loss: 0.0121\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0394 - model_3_loss: 0.0307 - model_1_loss: 0.0088\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0366 - model_3_loss: 0.0271 - model_1_loss: 0.0095\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0354 - model_3_loss: 0.0254 - model_1_loss: 0.0100\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0397 - model_3_loss: 0.0249 - model_1_loss: 0.0148\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0432 - model_3_loss: 0.0266 - model_1_loss: 0.0166\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0460 - model_3_loss: 0.0353 - model_1_loss: 0.0108\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0486 - model_3_loss: 0.0342 - model_1_loss: 0.0144\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0557 - model_3_loss: 0.0403 - model_1_loss: 0.0154\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0566 - model_3_loss: 0.0382 - model_1_loss: 0.0185\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0633 - model_3_loss: 0.0397 - model_1_loss: 0.0236\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0606 - model_3_loss: 0.0347 - model_1_loss: 0.0258\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0791 - model_3_loss: 0.0353 - model_1_loss: 0.0438\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0708 - model_3_loss: 0.0317 - model_1_loss: 0.0391\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0461 - model_3_loss: 0.0264 - model_1_loss: 0.0198\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0486 - model_3_loss: 0.0372 - model_1_loss: 0.0114\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0412 - model_3_loss: 0.0270 - model_1_loss: 0.0142\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0531 - model_3_loss: 0.0404 - model_1_loss: 0.0127\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0633 - model_3_loss: 0.0497 - model_1_loss: 0.0136\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0861 - model_3_loss: 0.0610 - model_1_loss: 0.0251\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0739 - model_3_loss: 0.0525 - model_1_loss: 0.0213\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0483 - model_3_loss: 0.0326 - model_1_loss: 0.0157\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0462 - model_3_loss: 0.0363 - model_1_loss: 0.0099\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0487 - model_3_loss: 0.0355 - model_1_loss: 0.0133\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0611 - model_3_loss: 0.0449 - model_1_loss: 0.0162\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0883 - model_3_loss: 0.0536 - model_1_loss: 0.0348\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0697 - model_3_loss: 0.0429 - model_1_loss: 0.0268\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0554 - model_3_loss: 0.0368 - model_1_loss: 0.0186\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0460 - model_3_loss: 0.0362 - model_1_loss: 0.0098\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0408 - model_3_loss: 0.0295 - model_1_loss: 0.0114\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0422 - model_3_loss: 0.0292 - model_1_loss: 0.0130\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0591 - model_3_loss: 0.0462 - model_1_loss: 0.0129\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0593 - model_3_loss: 0.0400 - model_1_loss: 0.0193\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0443 - model_3_loss: 0.0284 - model_1_loss: 0.0159\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0536 - model_3_loss: 0.0314 - model_1_loss: 0.0223\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0388 - model_3_loss: 0.0239 - model_1_loss: 0.0149\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0365 - model_3_loss: 0.0208 - model_1_loss: 0.0157\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0632 - model_3_loss: 0.0217 - model_1_loss: 0.0415\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0263 - model_3_loss: 0.0176 - model_1_loss: 0.0087\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0381 - model_3_loss: 0.0236 - model_1_loss: 0.0144\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0296 - model_3_loss: 0.0194 - model_1_loss: 0.0103\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0526 - model_3_loss: 0.0340 - model_1_loss: 0.0186\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0361 - model_3_loss: 0.0241 - model_1_loss: 0.0120\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0327 - model_3_loss: 0.0253 - model_1_loss: 0.0074\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0253 - model_3_loss: 0.0158 - model_1_loss: 0.0095\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0471 - model_3_loss: 0.0345 - model_1_loss: 0.0126\n",
      "Epoch 257/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0320 - model_3_loss: 0.0221 - model_1_loss: 0.0099\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0357 - model_3_loss: 0.0271 - model_1_loss: 0.0086\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0244 - model_3_loss: 0.0170 - model_1_loss: 0.0074\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0179 - model_3_loss: 0.0132 - model_1_loss: 0.0048\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0263 - model_3_loss: 0.0197 - model_1_loss: 0.0065\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0306 - model_3_loss: 0.0247 - model_1_loss: 0.0058\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0314 - model_3_loss: 0.0241 - model_1_loss: 0.0073\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0318 - model_3_loss: 0.0241 - model_1_loss: 0.0077\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0303 - model_3_loss: 0.0208 - model_1_loss: 0.0095\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0453 - model_3_loss: 0.0290 - model_1_loss: 0.0163\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0357 - model_3_loss: 0.0240 - model_1_loss: 0.0117\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0326 - model_3_loss: 0.0254 - model_1_loss: 0.0072\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0355 - model_3_loss: 0.0289 - model_1_loss: 0.0066\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0406 - model_3_loss: 0.0344 - model_1_loss: 0.0062\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0439 - model_3_loss: 0.0367 - model_1_loss: 0.0071\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0385 - model_3_loss: 0.0307 - model_1_loss: 0.0078\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0303 - model_3_loss: 0.0231 - model_1_loss: 0.0072\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0261 - model_3_loss: 0.0203 - model_1_loss: 0.0059\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0222 - model_3_loss: 0.0151 - model_1_loss: 0.0070\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0334 - model_3_loss: 0.0261 - model_1_loss: 0.0073\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0373 - model_3_loss: 0.0275 - model_1_loss: 0.0098\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0463 - model_3_loss: 0.0342 - model_1_loss: 0.0120\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0341 - model_3_loss: 0.0264 - model_1_loss: 0.0078\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0354 - model_3_loss: 0.0259 - model_1_loss: 0.0095\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0440 - model_3_loss: 0.0344 - model_1_loss: 0.0097\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0442 - model_3_loss: 0.0294 - model_1_loss: 0.0148\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0587 - model_3_loss: 0.0355 - model_1_loss: 0.0232\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0293 - model_3_loss: 0.0188 - model_1_loss: 0.0105\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0275 - model_3_loss: 0.0178 - model_1_loss: 0.0097\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0302 - model_3_loss: 0.0246 - model_1_loss: 0.0056\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0463 - model_3_loss: 0.0333 - model_1_loss: 0.0130\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0340 - model_3_loss: 0.0266 - model_1_loss: 0.0075\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0297 - model_3_loss: 0.0213 - model_1_loss: 0.0083\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0327 - model_3_loss: 0.0232 - model_1_loss: 0.0095\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0298 - model_3_loss: 0.0198 - model_1_loss: 0.0100\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0249 - model_3_loss: 0.0164 - model_1_loss: 0.0086\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0159 - model_3_loss: 0.0101 - model_1_loss: 0.0058\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0149 - model_3_loss: 0.0092 - model_1_loss: 0.0057\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0186 - model_3_loss: 0.0141 - model_1_loss: 0.0046\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0200 - model_3_loss: 0.0156 - model_1_loss: 0.0044\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0205 - model_3_loss: 0.0171 - model_1_loss: 0.0033\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0211 - model_3_loss: 0.0180 - model_1_loss: 0.0031\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0228 - model_3_loss: 0.0200 - model_1_loss: 0.0028\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0186 - model_3_loss: 0.0152 - model_1_loss: 0.0034\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0236 - model_3_loss: 0.0197 - model_1_loss: 0.0039\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0345 - model_3_loss: 0.0298 - model_1_loss: 0.0048\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0318 - model_3_loss: 0.0243 - model_1_loss: 0.0074\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0335 - model_3_loss: 0.0245 - model_1_loss: 0.0089\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0258 - model_3_loss: 0.0189 - model_1_loss: 0.0069\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0246 - model_3_loss: 0.0193 - model_1_loss: 0.0054\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0196 - model_3_loss: 0.0157 - model_1_loss: 0.0038\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0235 - model_3_loss: 0.0195 - model_1_loss: 0.0041\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0334 - model_3_loss: 0.0267 - model_1_loss: 0.0067\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0181 - model_3_loss: 0.0137 - model_1_loss: 0.0043\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0227 - model_3_loss: 0.0178 - model_1_loss: 0.0049\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0264 - model_3_loss: 0.0190 - model_1_loss: 0.0073\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0254 - model_3_loss: 0.0163 - model_1_loss: 0.0090\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0298 - model_3_loss: 0.0173 - model_1_loss: 0.0125\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0316 - model_3_loss: 0.0171 - model_1_loss: 0.0144\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0265 - model_3_loss: 0.0197 - model_1_loss: 0.0068\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0250 - model_3_loss: 0.0198 - model_1_loss: 0.0052\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0237 - model_3_loss: 0.0179 - model_1_loss: 0.0058\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0226 - model_3_loss: 0.0183 - model_1_loss: 0.0043\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0330 - model_3_loss: 0.0256 - model_1_loss: 0.0074\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0363 - model_3_loss: 0.0299 - model_1_loss: 0.0064\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0381 - model_3_loss: 0.0329 - model_1_loss: 0.0052\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0808 - model_3_loss: 0.0676 - model_1_loss: 0.0132\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0711 - model_3_loss: 0.0543 - model_1_loss: 0.0168\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0683 - model_3_loss: 0.0526 - model_1_loss: 0.0157\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0722 - model_3_loss: 0.0504 - model_1_loss: 0.0218\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0890 - model_3_loss: 0.0621 - model_1_loss: 0.0269\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0996 - model_3_loss: 0.0687 - model_1_loss: 0.0309\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1156 - model_3_loss: 0.0725 - model_1_loss: 0.0431\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1159 - model_3_loss: 0.0867 - model_1_loss: 0.0291\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1450 - model_3_loss: 0.1032 - model_1_loss: 0.0418\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1636 - model_3_loss: 0.1228 - model_1_loss: 0.0408\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2063 - model_3_loss: 0.1364 - model_1_loss: 0.0699\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2079 - model_3_loss: 0.1280 - model_1_loss: 0.0799\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1489 - model_3_loss: 0.1012 - model_1_loss: 0.0477\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1162 - model_3_loss: 0.0809 - model_1_loss: 0.0353\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0891 - model_3_loss: 0.0636 - model_1_loss: 0.0256\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0717 - model_3_loss: 0.0460 - model_1_loss: 0.0257\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0856 - model_3_loss: 0.0553 - model_1_loss: 0.0303\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0693 - model_3_loss: 0.0503 - model_1_loss: 0.0190\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0573 - model_3_loss: 0.0388 - model_1_loss: 0.0185\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0499 - model_3_loss: 0.0361 - model_1_loss: 0.0138\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0393 - model_3_loss: 0.0293 - model_1_loss: 0.0100\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0426 - model_3_loss: 0.0321 - model_1_loss: 0.0105\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0544 - model_3_loss: 0.0401 - model_1_loss: 0.0143\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0423 - model_3_loss: 0.0311 - model_1_loss: 0.0111\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0333 - model_3_loss: 0.0248 - model_1_loss: 0.0085\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0352 - model_3_loss: 0.0275 - model_1_loss: 0.0077\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0317 - model_3_loss: 0.0252 - model_1_loss: 0.0066\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0290 - model_3_loss: 0.0224 - model_1_loss: 0.0066\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0334 - model_3_loss: 0.0271 - model_1_loss: 0.0063\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0230 - model_3_loss: 0.0201 - model_1_loss: 0.0029\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0208 - model_3_loss: 0.0174 - model_1_loss: 0.0033\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0220 - model_3_loss: 0.0183 - model_1_loss: 0.0037\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0242 - model_3_loss: 0.0209 - model_1_loss: 0.0033\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0163 - model_3_loss: 0.0138 - model_1_loss: 0.0025\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0218 - model_3_loss: 0.0179 - model_1_loss: 0.0039\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0276 - model_3_loss: 0.0233 - model_1_loss: 0.0043\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0148 - model_3_loss: 0.0118 - model_1_loss: 0.0029\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0150 - model_3_loss: 0.0118 - model_1_loss: 0.0031\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0192 - model_3_loss: 0.0164 - model_1_loss: 0.0028\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0121 - model_3_loss: 0.0097 - model_1_loss: 0.0024\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0239 - model_3_loss: 0.0209 - model_1_loss: 0.0030\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0162 - model_3_loss: 0.0136 - model_1_loss: 0.0026\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0204 - model_3_loss: 0.0179 - model_1_loss: 0.0025\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0155 - model_3_loss: 0.0137 - model_1_loss: 0.0018\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0169 - model_3_loss: 0.0146 - model_1_loss: 0.0023\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0150 - model_3_loss: 0.0131 - model_1_loss: 0.0019\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0186 - model_3_loss: 0.0149 - model_1_loss: 0.0037\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0179 - model_3_loss: 0.0156 - model_1_loss: 0.0023\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0142 - model_3_loss: 0.0112 - model_1_loss: 0.0029\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0183 - model_3_loss: 0.0144 - model_1_loss: 0.0039\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0257 - model_3_loss: 0.0228 - model_1_loss: 0.0030\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0223 - model_3_loss: 0.0190 - model_1_loss: 0.0033\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0750 - model_3_loss: 0.0640 - model_1_loss: 0.0110\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1464 - model_3_loss: 0.1124 - model_1_loss: 0.0340\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1068 - model_3_loss: 0.0794 - model_1_loss: 0.0274\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1129 - model_3_loss: 0.0861 - model_1_loss: 0.0268\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2209 - model_3_loss: 0.1609 - model_1_loss: 0.0600\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2664 - model_3_loss: 0.1971 - model_1_loss: 0.0693\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2452 - model_3_loss: 0.1685 - model_1_loss: 0.0767\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2733 - model_3_loss: 0.1659 - model_1_loss: 0.1074\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1913 - model_3_loss: 0.1290 - model_1_loss: 0.0623\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2079 - model_3_loss: 0.1501 - model_1_loss: 0.0579\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1823 - model_3_loss: 0.1289 - model_1_loss: 0.0534\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0926 - model_3_loss: 0.0603 - model_1_loss: 0.0323\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0795 - model_3_loss: 0.0533 - model_1_loss: 0.0262\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0735 - model_3_loss: 0.0561 - model_1_loss: 0.0175\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0606 - model_3_loss: 0.0419 - model_1_loss: 0.0186\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0451 - model_3_loss: 0.0243 - model_1_loss: 0.0209\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0452 - model_3_loss: 0.0276 - model_1_loss: 0.0176\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0401 - model_3_loss: 0.0259 - model_1_loss: 0.0142\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0492 - model_3_loss: 0.0330 - model_1_loss: 0.0162\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0449 - model_3_loss: 0.0289 - model_1_loss: 0.0160\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0492 - model_3_loss: 0.0383 - model_1_loss: 0.0110\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0316 - model_3_loss: 0.0224 - model_1_loss: 0.0091\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0502 - model_3_loss: 0.0423 - model_1_loss: 0.0079\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0471 - model_3_loss: 0.0396 - model_1_loss: 0.0075\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0340 - model_3_loss: 0.0265 - model_1_loss: 0.0075\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0354 - model_3_loss: 0.0248 - model_1_loss: 0.0106\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0338 - model_3_loss: 0.0218 - model_1_loss: 0.0120\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0231 - model_3_loss: 0.0158 - model_1_loss: 0.0072\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0124 - model_3_loss: 0.0094 - model_1_loss: 0.0030\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0147 - model_3_loss: 0.0119 - model_1_loss: 0.0028\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0207 - model_3_loss: 0.0164 - model_1_loss: 0.0043\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0157 - model_3_loss: 0.0124 - model_1_loss: 0.0033\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0160 - model_3_loss: 0.0125 - model_1_loss: 0.0035\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0120 - model_3_loss: 0.0098 - model_1_loss: 0.0022\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0125 - model_3_loss: 0.0111 - model_1_loss: 0.0014\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0182 - model_3_loss: 0.0164 - model_1_loss: 0.0018\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0133 - model_3_loss: 0.0121 - model_1_loss: 0.0011\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - model_3_loss: 0.0145 - model_1_loss: 0.0014\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0156 - model_3_loss: 0.0143 - model_1_loss: 0.0013\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0119 - model_3_loss: 0.0102 - model_1_loss: 0.0017\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0121 - model_3_loss: 0.0110 - model_1_loss: 0.0011\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0087 - model_3_loss: 0.0076 - model_1_loss: 0.0010\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0103 - model_3_loss: 0.0090 - model_1_loss: 0.0012\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0095 - model_3_loss: 0.0077 - model_1_loss: 0.0018\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0123 - model_3_loss: 0.0103 - model_1_loss: 0.0020\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0109 - model_3_loss: 0.0093 - model_1_loss: 0.0016\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0106 - model_3_loss: 0.0091 - model_1_loss: 0.0016\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0103 - model_3_loss: 0.0089 - model_1_loss: 0.0013\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0125 - model_3_loss: 0.0109 - model_1_loss: 0.0016\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0105 - model_3_loss: 0.0090 - model_1_loss: 0.0016\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0127 - model_3_loss: 0.0113 - model_1_loss: 0.0013\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0081 - model_3_loss: 0.0070 - model_1_loss: 0.0011\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0271 - model_3_loss: 0.0236 - model_1_loss: 0.0036\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0128 - model_3_loss: 0.0111 - model_1_loss: 0.0017\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0085 - model_3_loss: 0.0071 - model_1_loss: 0.0014\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0136 - model_3_loss: 0.0123 - model_1_loss: 0.0013\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0137 - model_3_loss: 0.0123 - model_1_loss: 0.0013\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0133 - model_3_loss: 0.0117 - model_1_loss: 0.0016\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0122 - model_3_loss: 0.0106 - model_1_loss: 0.0016\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0093 - model_3_loss: 0.0081 - model_1_loss: 0.0012\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0121 - model_3_loss: 0.0106 - model_1_loss: 0.0015\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0132 - model_3_loss: 0.0118 - model_1_loss: 0.0014\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0145 - model_3_loss: 0.0131 - model_1_loss: 0.0014\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0134 - model_3_loss: 0.0121 - model_1_loss: 0.0013\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0213 - model_3_loss: 0.0192 - model_1_loss: 0.0021\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0193 - model_3_loss: 0.0159 - model_1_loss: 0.0034\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0291 - model_3_loss: 0.0256 - model_1_loss: 0.0035\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0382 - model_3_loss: 0.0329 - model_1_loss: 0.0053\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0211 - model_3_loss: 0.0163 - model_1_loss: 0.0048\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0218 - model_3_loss: 0.0188 - model_1_loss: 0.0030\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0172 - model_3_loss: 0.0133 - model_1_loss: 0.0039\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0156 - model_3_loss: 0.0110 - model_1_loss: 0.0046\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0161 - model_3_loss: 0.0133 - model_1_loss: 0.0029\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0224 - model_3_loss: 0.0187 - model_1_loss: 0.0037\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0212 - model_3_loss: 0.0184 - model_1_loss: 0.0028\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0199 - model_3_loss: 0.0166 - model_1_loss: 0.0033\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0159 - model_3_loss: 0.0132 - model_1_loss: 0.0027\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0198 - model_3_loss: 0.0161 - model_1_loss: 0.0037\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0361 - model_3_loss: 0.0323 - model_1_loss: 0.0037\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0366 - model_3_loss: 0.0308 - model_1_loss: 0.0057\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0386 - model_3_loss: 0.0326 - model_1_loss: 0.0060\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0208 - model_3_loss: 0.0166 - model_1_loss: 0.0042\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0249 - model_3_loss: 0.0190 - model_1_loss: 0.0058\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0244 - model_3_loss: 0.0199 - model_1_loss: 0.0045\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0231 - model_3_loss: 0.0207 - model_1_loss: 0.0024\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0216 - model_3_loss: 0.0188 - model_1_loss: 0.0027\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0206 - model_3_loss: 0.0180 - model_1_loss: 0.0026\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0380 - model_3_loss: 0.0335 - model_1_loss: 0.0045\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0269 - model_3_loss: 0.0226 - model_1_loss: 0.0042\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0199 - model_3_loss: 0.0163 - model_1_loss: 0.0035\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0234 - model_3_loss: 0.0146 - model_1_loss: 0.0088\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0287 - model_3_loss: 0.0136 - model_1_loss: 0.0151\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0315 - model_3_loss: 0.0200 - model_1_loss: 0.0115\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0259 - model_3_loss: 0.0204 - model_1_loss: 0.0055\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0267 - model_3_loss: 0.0198 - model_1_loss: 0.0068\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0177 - model_3_loss: 0.0140 - model_1_loss: 0.0038\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0308 - model_3_loss: 0.0231 - model_1_loss: 0.0077\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0314 - model_3_loss: 0.0266 - model_1_loss: 0.0048\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0214 - model_3_loss: 0.0174 - model_1_loss: 0.0041\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0244 - model_3_loss: 0.0202 - model_1_loss: 0.0042\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0350 - model_3_loss: 0.0293 - model_1_loss: 0.0057\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0475 - model_3_loss: 0.0412 - model_1_loss: 0.0063\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0959 - model_3_loss: 0.0868 - model_1_loss: 0.0091\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1093 - model_3_loss: 0.0869 - model_1_loss: 0.0224\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1069 - model_3_loss: 0.0888 - model_1_loss: 0.0181\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2067 - model_3_loss: 0.1257 - model_1_loss: 0.0809\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2585 - model_3_loss: 0.1577 - model_1_loss: 0.1008\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2101 - model_3_loss: 0.1437 - model_1_loss: 0.0664\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3482 - model_3_loss: 0.2121 - model_1_loss: 0.1361\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2951 - model_3_loss: 0.1671 - model_1_loss: 0.1281\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2503 - model_3_loss: 0.1454 - model_1_loss: 0.1049\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1352 - model_3_loss: 0.0944 - model_1_loss: 0.0408\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1001 - model_3_loss: 0.0765 - model_1_loss: 0.0236\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0931 - model_3_loss: 0.0746 - model_1_loss: 0.0185\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1004 - model_3_loss: 0.0730 - model_1_loss: 0.0274\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0508 - model_3_loss: 0.0394 - model_1_loss: 0.0113\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0606 - model_3_loss: 0.0521 - model_1_loss: 0.0085\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0429 - model_3_loss: 0.0358 - model_1_loss: 0.0070\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0361 - model_3_loss: 0.0314 - model_1_loss: 0.0047\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0238 - model_3_loss: 0.0198 - model_1_loss: 0.0040\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0247 - model_3_loss: 0.0212 - model_1_loss: 0.0035\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0342 - model_3_loss: 0.0306 - model_1_loss: 0.0035\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0428 - model_3_loss: 0.0385 - model_1_loss: 0.0043\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0236 - model_3_loss: 0.0201 - model_1_loss: 0.0035\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0277 - model_3_loss: 0.0251 - model_1_loss: 0.0026\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0399 - model_3_loss: 0.0352 - model_1_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31c854cd90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([x_train_scaled, y_train_scaled], [x_train_scaled, tf.zeros_like(model_psi(x_train_scaled))], epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7be37ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_layer = model_koopman.get_layer('k_layer')\n",
    "matrix = k_layer.trainable_variables[0]\n",
    "eigenvalues, eigenvectors = tf.linalg.eig(matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Extract real and imaginary parts\n",
    "real_part = np.real(eigenvalues)\n",
    "imag_part = np.imag(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e80587a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=complex64, numpy=\n",
       "array([-0.24507616+0.j        ,  0.04750601+0.2632461j ,\n",
       "        0.04750601-0.2632461j , -0.03667491+0.16716656j,\n",
       "       -0.03667491-0.16716656j, -0.07713522+0.j        ,\n",
       "        0.33454126+0.37062612j,  0.33454126-0.37062612j,\n",
       "        0.25770074+0.j        ,  0.21524322+0.j        ,\n",
       "        0.4460876 +0.10361753j,  0.4460876 -0.10361753j,\n",
       "        0.5618807 +0.j        ,  0.6905519 +0.06277397j,\n",
       "        0.6905519 -0.06277397j,  0.7666549 +0.j        ,\n",
       "        0.81831986+0.j        ,  0.91442907+0.03104459j,\n",
       "        0.91442907-0.03104459j,  0.87547994+0.j        ,\n",
       "        0.9985927 +0.00693331j,  0.9985927 -0.00693331j,\n",
       "        0.99673414+0.j        ,  1.0088536 +0.j        ,\n",
       "        1.0044203 +0.00398749j,  1.0044203 -0.00398749j,\n",
       "        1.00246   +0.00189761j,  1.00246   -0.00189761j,\n",
       "        1.0063869 +0.00074651j,  1.0063869 -0.00074651j,\n",
       "        1.0040811 +0.00266348j,  1.0040811 -0.00266348j], dtype=complex64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38ab5331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAHFCAYAAABGs3gVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACAEklEQVR4nO3dd3gUVRfA4d+mF5IACaRQkgDSO0iVLlWKooCINBEplg+wIBaKDbEANkCKgIICShekSJcivfcaJAmBAGmQPt8fQzZZ0rM7W5LzPs8+mZ2d2XsmW87OnVt0iqIoCCGEEKJA7CwdgBBCCGHLJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQohhBBGkEQqhBBCGEESqRBCCGEESaRCCCGEEYpcIl2wYAE6nS7b2/bt2/XbBgUFMWjQIIvFqrXWrVvTunVrS4eRoxkzZrBgwYI8b//nn38yYMAAatWqhaOjIzqdLsftT548Sa9evShVqhTOzs4EBQUxcuRII6M2rcL8Pkz7PF69ejXH7f7++2/at29PQEAAzs7OlC5dmrZt27J+/XqD7aKjo/n0009p3bo1fn5+FCtWjFq1ajFlyhTi4+MLHOfVq1fR6XQG78WJEyfm+v4yhe3bt2f6bsqr06dPM3HixFz/v6by2WefsWrVKpM9nyni37NnDxMnTuTevXsmi+tRRS6Rppk/fz579+7NdKtfv75+m5UrV/Lhhx9aMEqR30S6cuVK9u3bR/Xq1alTp06O227bto1GjRoRHR3NrFmz2LRpEx9//DEuLi5GRi1MLTIykho1ajBt2jQ2bdrEjz/+iKOjI0899RSLFi3SbxcSEsL06dOpX78+s2fPZs2aNTz33HNMnDiRrl27YsoRUV9++WX27t1rsufTwunTp5k0aZJNJ1Jj49+zZw+TJk3SNJE6aPbMVq5mzZo0bNgwx23q1atnpmiEqcyZMwc7O/X34WuvvcahQ4ey3O7+/fv069ePtm3bsnbtWoMzi/79+5slVpF3ffr0oU+fPgbrunbtSnBwMLNnz+bFF18EIDg4mKtXr+Lu7q7frm3btri7u/P222+ze/dunnjiCZPEVLZsWcqWLWuS5xK2rciekeZFVlVqp06dokOHDri5uVGqVCleffVV1q1bl2XVy99//027du3w9PTEzc2N5s2bs2XLFoNt0qqHTp06Rd++ffHy8sLX15eXXnqJqKgo/Xb16tWjRYsWmWJMSUmhTJky9OzZU79u0qRJNG7cmJIlS+Lp6Un9+vWZN29err/Gs6tCyqpaC+DgwYN0796dkiVL4uLiQr169Vi2bFmOZeQnxqCgIE6dOsWOHTv0Ve9BQUE5Pm9aEs3N77//TlhYGG+//XaBqufy+roBxMfHM27cOIKDg3FycqJMmTK8+uqrmX4hJyUl8c477+Dn54ebmxtPPPEE+/fvz7L88PBwhg0bRtmyZXFyciI4OJhJkyaRnJxssN3MmTOpU6cOxYoVw8PDg6pVq/Lee+/lenx5fQ8FBQXRtWtXNmzYQP369XF1daVq1ar89NNPmZ5z3759NG/eHBcXFwICAhg3bhxJSUm5xpIdR0dHihcvjoND+vmAu7u7QRJN06hRIwCuX7+e6/OGhobSu3dvPDw88PLyok+fPoSHh2faLquq3bT/x59//km9evVwdXWlWrVq/Pnnn4BalV2tWjXc3d1p1KgRBw8ezNcxpzl48CDPP/88QUFBuLq6EhQURN++fbl27Zp+mwULFtCrVy8A2rRpo/8MZfwcm/I7SqfTERcXx8KFC/Vl5XbpKKf3Z27xb968mR49elC2bFlcXFyoVKkSw4YN4/bt2waxv/3224D6IyurS3hLly6ladOmuLu7U6xYMTp27MiRI0fy9kI8VGTPSFNSUjJ96eh0Ouzt7bPdJywsjFatWuHu7s7MmTMpXbo0v/32G6+99lqmbRctWsSAAQPo0aMHCxcuxNHRkR9//JGOHTuyceNG2rVrZ7D9s88+S58+fRgyZAgnTpxg3LhxAPovpMGDB/O///2PCxcu8Nhjj+n327RpE6GhoQwePFi/7urVqwwbNozy5csD6hfY66+/zo0bNxg/fnw+/1NZ27ZtG506daJx48bMmjULLy8vlixZQp8+fbh//36u1/TyEuPKlSt57rnn8PLyYsaMGQA4OzubJP6dO3cC6vsgLWG5u7vTqVMnvv76awICAvL0PLm9boqi8PTTT7NlyxbGjRtHixYtOH78OBMmTNBfTkg7pqFDh/Lzzz/z1ltv0b59e06ePEnPnj2JiYkxKDM8PJxGjRphZ2fH+PHjqVixInv37uWTTz7h6tWrzJ8/H4AlS5YwcuRIXn/9db766ivs7Oy4ePEip0+fzvW48vMeOnbsGG+++Sbvvvsuvr6+zJ07lyFDhlCpUiVatmwJqFV07dq1IygoiAULFuDm5saMGTP49ddf8/R/TpOamkpqaioRERH8+OOPnD9/nilTpuS639atWwGoUaNGjts9ePCAJ598ktDQUCZPnkzlypVZt25dprPhnBw7doxx48bx/vvv4+XlxaRJk+jZsyfjxo1jy5YtfPbZZ+h0OsaOHUvXrl25cuUKrq6ueX5+UF+fKlWq8Pzzz1OyZEnCwsKYOXMmjz/+OKdPn8bHx4ennnqKzz77jPfee48ffvhBf9mqYsWKgOm/o/bu3Uvbtm1p06aN/pKYp6dntseQ2/szt/gvXbpE06ZNefnll/Hy8uLq1atMnTqVJ554ghMnTuDo6MjLL7/MnTt3+O6771ixYgX+/v4AVK9eHVCroj/44AMGDx7MBx98QGJiIl9++SUtWrRg//79+u1ypRQx8+fPV4Asb/b29gbbBgYGKgMHDtTff/vttxWdTqecOnXKYLuOHTsqgLJt2zZFURQlLi5OKVmypNKtWzeD7VJSUpQ6deoojRo10q+bMGGCAihffPGFwbYjR45UXFxclNTUVEVRFOX27duKk5OT8t577xls17t3b8XX11dJSkrK8nhTUlKUpKQk5aOPPlK8vb31z6coitKqVSulVatW+vvbtm0zOI40V65cUQBl/vz5+nVVq1ZV6tWrl6ncrl27Kv7+/kpKSkqW8eQ3xho1ahjEmB+vvvqqkt1bPO01K168uPLOO+8oW7duVWbNmqV4e3srlSpVUuLi4nJ87ry+bhs2bMhyu6VLlyqAMnv2bEVRFOXMmTMKoIwePdpgu8WLFyuAwftw2LBhSrFixZRr164ZbPvVV18pgP79+dprrynFixfP8TjyIqfXJzAwUHFxcTGI5cGDB0rJkiWVYcOG6df16dNHcXV1VcLDw/XrkpOTlapVqyqAcuXKlTzFkva6AYqnp6eyYsWKXPc5duyY4urqqjzzzDO5bjtz5kwFUFavXm2wfujQoZk+A2nvgYwCAwMVV1dX5b///tOvO3r0qAIo/v7+Bu+rVatWKYCyZs2aHGPK7nOZUXJyshIbG6u4u7sr33zzjX7977//nuW+WnxHKYqiuLu7G7xXc5KX92d28T8qNTVVSUpKUq5du5bp9fvyyy+zfI+FhIQoDg4Oyuuvv26wPiYmRvHz81N69+6dp+NQFEUpslW7P//8MwcOHDC4/fvvvznus2PHDmrWrJnpV0rfvn0N7u/Zs4c7d+4wcOBAkpOT9bfU1FQ6derEgQMHiIuLM9ine/fuBvdr165NfHw8ERERAHh7e9OtWzcWLlxIamoqAHfv3mX16tUMGDDAoHpr69atPPnkk3h5eWFvb4+joyPjx48nMjJS/3zGuHjxImfPnqVfv34ABsfYpUsXwsLCOHfuXI7PoXWMuUn7H/bp04cpU6bQpk0bhg0bxrx587h48WKez5Rye93SzoQePUPv1asX7u7u+mq0bdu2Aej/p2l69+5t8NqC2jK5TZs2BAQEGPzvO3fuDKjvU1CrM+/du0ffvn1ZvXq1QZVXbvLz+tStW1d/5grg4uJC5cqVDaoZt23bRrt27fD19dWvs7e3z9eZHsB3333H/v37Wb16NR07dqRPnz789ttv2W5/9epVunbtSrly5Zg7d26uz79t2zY8PDwyva4vvPBCnmOsW7cuZcqU0d+vVq0aoLaSd3Nzy7Q+4/8pr2JjYxk7diyVKlXCwcEBBwcHihUrRlxcHGfOnMl1fy2+o/LLmPcnQEREBMOHD6dcuXI4ODjg6OhIYGAgQJ7+Bxs3biQ5OZkBAwYY/A9cXFxo1apVvlpJF9mq3WrVquXa2OhRkZGRBAcHZ1qf8csB4ObNmwA899xz2T7XnTt3DK7leHt7GzyeVt334MED/bqXXnqJ5cuXs3nzZjp27Mhvv/1GQkKCwZf0/v376dChA61bt2bOnDn6a2irVq3i008/NXi+gko7vrfeeou33nory21y+lCYI8bcpP2/O3bsaLC+Y8eO6HQ6Dh8+nK/nSfPo6xYZGYmDgwOlSpUy2E6n0+Hn50dkZKR+OwA/Pz+D7RwcHDKVcfPmTdauXYujo2OWMaX97/v3709ycjJz5szh2WefJTU1lccff5xPPvmE9u3bZ3tM+X19Ho0v7f+QcbvIyMhMx5bV8eYm42WN7t2707lzZ1599VX69OmT6fr4tWvXaNOmDQ4ODmzZsoWSJUvm+vyRkZGZPs/5jfPRcpycnHJcX5BuOS+88AJbtmzhww8/5PHHH8fT0xOdTkeXLl3y9PnR6jsqPwr6/gT1h3CHDh0IDQ3lww8/pFatWri7u5OamkqTJk3y9T94/PHHs3w8r+0toAgn0oLw9vbW//MzerQhgo+PD6D+em7SpEmWz5XVhzU3HTt2JCAggPnz59OxY0fmz59P48aNDc6QlyxZgqOjI3/++adBN468NElP2z4hIcFg/aNJMe34xo0bZ9DIKaMqVapkW44xMZpK7dq1WbJkSbaP5+dDlBNvb2+Sk5O5deuWQTJVFIXw8HD9hzjtSyo8PNzgbCY5OVmfZNP4+PhQu3ZtPv300yzLzHh9d/DgwQwePJi4uDh27tzJhAkT6Nq1K+fPn9f/en+UFq+Pt7d3lg12slqXH40aNWLDhg3cunXL4DN17do1WrdujaIobN++Pc+ta729vbNs4GVsnKYUFRXFn3/+yYQJE3j33Xf16xMSErhz506enkOr76j8Ksj7E9T+38eOHWPBggUMHDhQv/7ixYt5Ljvtf/DHH3/kWFZeSCLNh1atWvHVV19x+vTpTMkro+bNm1O8eHFOnz6dZUOkgrK3t6d///5Mnz6dXbt2cfDgQX788UeDbXQ6HQ4ODgaNph48eMAvv/yS6/OntYg9fvy4wZnamjVrDLarUqUKjz32GMeOHeOzzz7L93HkJ8ZHz2xM5ZlnnuH999/nr7/+4plnntGv/+uvv1AUJdsvl/xq164dX3zxBYsWLWL06NH69cuXLycuLk7foCOtdePixYtp0KCBfrtly5ZlahTXtWtX1q9fT8WKFSlRokSe4nB3d6dz584kJiby9NNPc+rUqWy/PIx5D2WnTZs2rFmzhps3b+q/oFNSUli6dGmBn1NRFHbs2EHx4sUNzpZCQkJo3bo1KSkpbN++PV9fkm3atGHZsmWsWbPGoCozv42itKTT6VAUJVPDu7lz55KSkmKwLruzRq2+owr6ec3u/Zld/GmtpR/9Hzz6fZhxm0efo2PHjjg4OHDp0iWeffbZfMecUZFNpCdPnsz0BQVqi7BHq+HSjBo1ip9++onOnTvz0Ucf4evry6+//srZs2eB9LOYYsWK8d133zFw4EDu3LnDc889R+nSpbl16xbHjh3j1q1bzJw5s0Bxv/TSS0yZMoUXXngBV1fXTNeYnnrqKaZOncoLL7zAK6+8QmRkJF999VWeWrv6+fnx5JNPMnnyZEqUKEFgYCBbtmxhxYoVmbb98ccf6dy5Mx07dmTQoEGUKVOGO3fucObMGQ4fPszvv/+ebTn5ibFWrVosWbKEpUuXUqFCBVxcXKhVq1a2z33t2jUOHDgAqK36QP3FCeoPhbTq/KpVq/Lqq68yY8YMPDw86Ny5M+fPn+eDDz6gXr169O7dO9f/V160b9+ejh07MnbsWKKjo2nevLm+1W69evX0fVarVavGiy++yPTp03F0dOTJJ5/k5MmTfPXVV5laPn700Uds3ryZZs2a8cYbb1ClShXi4+O5evUq69evZ9asWZQtW5ahQ4fi6upK8+bN8ff3Jzw8nMmTJ+Pl5ZVtdRYY9x7KzgcffMCaNWto27Yt48ePx83NjR9++CHTdbjs9OjRgzp16lC3bl28vb0JDQ1lwYIF7Nixgx9++EF/HTkiIoI2bdoQFhbGvHnziIiIMLiGl1vfzwEDBjBt2jQGDBjAp59+ymOPPcb69evZuHFjgY/d1Dw9PWnZsiVffvklPj4+BAUFsWPHDubNm0fx4sUNtq1ZsyYAs2fPxsPDAxcXF4KDg/H29tbkO6pWrVps376dtWvX4u/vj4eHR7a1U3l5f2YXf9WqValYsSLvvvsuiqJQsmRJ1q5dy+bNm7OMCeCbb75h4MCBODo6UqVKFYKCgvjoo494//33uXz5Mp06daJEiRLcvHlT34p/0qRJeTvwPDdLKiRyarULKHPmzNFv+2irXUVRlJMnTypPPvmk4uLiopQsWVIZMmSIsnDhQgVQjh07ZrDtjh07lKeeekopWbKk4ujoqJQpU0Z56qmnlN9//12/TVqLuFu3bmUZZ1atGZs1a6YASr9+/bI8xp9++kmpUqWK4uzsrFSoUEGZPHmyMm/evEzP92irXUVRlLCwMOW5555TSpYsqXh5eSkvvviicvDgwUwtFhVFbQ3Zu3dvpXTp0oqjo6Pi5+entG3bVpk1a1aWcRUkxqtXryodOnRQPDw8FEAJDAzM8Xlzen0ffS2Tk5OVzz//XKlUqZLi6Oio+Pv7KyNGjFDu3r2ba/z5ed0ePHigjB07VgkMDMyxnISEBOXNN99USpcurbi4uChNmjRR9u7dm+X78NatW8obb7yhBAcHK46OjkrJkiWVBg0aKO+//74SGxurKIqiLFy4UGnTpo3i6+urODk5KQEBAUrv3r2V48eP53p8eX19AgMDlaeeeirT/lm9t3bv3q00adJEcXZ2Vvz8/JS3335bmT17dp5a7U6ZMkV5/PHHlRIlSij29vaKt7e30rFjR+XPP/802C6thWt2twkTJuR67P/995/y7LPPKsWKFVM8PDyUZ599VtmzZ0+eW+1m9f8AlFdffdVgXVpr+C+//DLHeLJqtZsWY4kSJRQPDw+lU6dOysmTJ7N8r0yfPl0JDg5W7O3tMx2Dqb+jjh49qjRv3lxxc3NTgBxb3Of1/Zld/KdPn1bat2+veHh4KCVKlFB69eqlhISEZPk6jxs3TgkICFDs7Owy/S9XrVqltGnTRvH09FScnZ2VwMBA5bnnnlP+/vvvbGN/lE5RTDhmVhH1yiuv8NtvvxEZGalvQCCEEKJoKLJVuwX10UcfERAQQIUKFYiNjeXPP/9k7ty5fPDBB5JEhRCiCJJEmk+Ojo58+eWX/PfffyQnJ/PYY48xdepU/ve//1k6NCGEEBYgVbtCCCGEEWxqZKOdO3fSrVs3AgIC0Ol0ufZrSxuE/dFbWitbIYQQwlg2VbUbFxdHnTp1GDx4cL76/Zw7d86gC0F23VuEEEKI/LKpRNq5c2f9eKL5Ubp06Uz9q4QQQghTsKlEWlD16tUjPj6e6tWr88EHH9CmTZtst01ISDAYIi81NZU7d+7g7e1doHkrhRBCWJaiKMTExBAQEGCy4T8zKtSJ1N/fn9mzZ9OgQQMSEhL45ZdfaNeuHdu3b9fPk/ioyZMn5300CyGEEDbj+vXreR53OT9sttWuTqdj5cqVPP300/nar1u3buh0ukzjx6Z59Iw0KiqK8uXLc/369RwnqRVCCGGdoqOjKVeuHPfu3cPLy8vkz1+oz0iz0qRJExYtWpTt487OzlmOKerp6SmJVAghbJhWl+dsqvuLKRw5cgR/f39LhyGEEKKQsKkz0tjYWIP55q5cucLRo0cpWbIk5cuXZ9y4cdy4cYOff/4ZgOnTpxMUFESNGjVITExk0aJFLF++nOXLl1vqEIQQQhQyNpVIDx48aNDidsyYMQAMHDiQBQsWEBYWRkhIiP7xxMRE3nrrLW7cuIGrqys1atRg3bp1dOnSxeyxCyGEKJxstrGRuURHR+Pl5UVUVJRcIxVCCBuk9fd4kbtGKoQQQpiSJFIhhBDCCJJIhRBCCCNIIhVCCCGMIIlUCCGEMIIkUiGEEMIIkkiFEEIII0giFUIIIYwgiVQIIYQwgiRSIYQQwgiSSIUQQggjSCIVQgghjCCJVAghhDCCJFIhhBDCCJJIhRBCCCNIIhVCCCGMIIlUCCGEMIIkUiGEEMIIkkiFEEIII0giFUIIIYwgiVQIIYQwgiRSIYQQwgiSSIUQQggjSCIVQgghjCCJVAghhDCCJFIhhBDCCJJIhRBCCCNIIhVCCCGMIIlUCCGEMIIkUiGEEMIIkkiFEEIII0giFUIIIYwgiVQIIYQwgiRSIYQQwgiSSIUQQggjSCIVQgghjCCJVAghhDCCJFIhhBDCCJJIhRBCCCNIIhVCCCGMIIlUCCGEMIIkUiGEEMIIkkiFEEIII0giFUIIIYwgiVQIIYQwgiRSIYQQwgiSSIUQQggjSCIVQgghjCCJVAghhDCCJFIhhBDCCDaVSHfu3Em3bt0ICAhAp9OxatWqXPfZsWMHDRo0wMXFhQoVKjBr1iztAxVCCFFk2FQijYuLo06dOnz//fd52v7KlSt06dKFFi1acOTIEd577z3eeOMNli9frnGkQgghigoHSweQH507d6Zz58553n7WrFmUL1+e6dOnA1CtWjUOHjzIV199xbPPPqtRlEIIIYoSm0qk+bV37146dOhgsK5jx47MmzePpKQkHB0dLRSZEBpSFEiMATtHcHRNXx99HfZ/DkoypCZDatLDv8mADuwdwc5B3a/F5+Dqnb5vbChEX4NiAeDmBw7OZj8sIaxVoU6k4eHh+Pr6Gqzz9fUlOTmZ27dv4+/vn2mfhIQEEhIS9Pejo6M1j1OIfElNhjtn4dZxiPkP4kIhNgziwtKXk+9Dtz+gcoaal/g7cGxG3spoOtHw/sVVsOXV9Psu3lDMH9z91eTq7g/uAeAVDBWeAp3O2KMUwmYU6kQKoHvkA60oSpbr00yePJlJkyZpHpcQBZKaAjNLQ/zd3LeNDTW8b5ePj/uj28aFGd6Pj1Rvt08arvcoBxVDDNfdOqGe3RYLyHv5QtiQQp1I/fz8CA8PN1gXERGBg4MD3t7eWe4zbtw4xowZo78fHR1NuXLlNI1TCCD9TPPmIfUWfhBKVILOP6dvY2cPXhUg/lDWz+FcPMNZomFtDF4V4MWDatWtnQPoHNTqXJ09oKjlpySpVb+uj3w+/JtCvdfVhBobmv43JcFwO98GmWPaNATCD4C7n/p46Qbg11BdluQqCoFCnUibNm3K2rVrDdZt2rSJhg0bZnt91NnZGWdnuf4jzOT+bbiyHi6tgasbISnW8PG40Mz7VOiqJsXS9aF4xQxVq/6G10Qf5eiadaLLiwpd1FtGigIJ9zIk1htQrKzhNilJahU0QFw4XF6n3tJ4BkHF7uqtbEs1sQthY2wqkcbGxnLx4kX9/StXrnD06FFKlixJ+fLlGTduHDdu3ODnn9Vf8MOHD+f7779nzJgxDB06lL179zJv3jx+++03Sx2CEKr/dsI/70PoHlBSs99OZw9JceDonr6u2UTNw8sTnQ5cSqg3nxpZb5P8AOr/L/0sO+Ge4ePRV+HIt+qt00KoMUDrqIUwOZtKpAcPHqRNmzb6+2lVsAMHDmTBggWEhYUREpJ+fSY4OJj169czevRofvjhBwICAvj222+l64swr7Qq04xni3aOcOMfw+1cfaBcG/Ws0bch+NZXk5Qtc/aEllPUZUWBqCsZqq73w41d6v9HZwfBj5zxhu6DsL3q2WrxiuaPXYg80ilprW9ElqKjo/Hy8iIqKgpPT09LhyNsRWoKXN0A55aqVZlNPoQGowwfn+WvXotMq9r0b6JeAy1KEqLUKu07Z6HpeMPHNg+H4z+qy97V1f9R9YHgXdX8cQqbpvX3uCTSXEgiFfly/xacmAfHZ6n9LtOUawO9tz6y7W1w8zFvfLZCUWB22cwtjwHKt4U6I6FSj/y1RBZFltbf4/IuFMJYigJh++DoDDi/DFISDR938lBbrCqpahVmGkmiOXvub7UR1qU1ELoXePibP2SreisWALVegTrD1P+vEBYiZ6S5kDNSkaPwg7BpKNw6+sgDOgjuBLWHq3/tnSwRXeFxPwLOLIZjM+HuBcPHeq6H4LwPHSqKHjkjFcKaufvB7RPp911KQs0h6lmSNJAxHbfS0GC02gL42hZ1hKZLa8AzEII6Gm5775LacMvZyzKxiiJHEqkQeRV+UB3NJ+MXt0dZ9Vpd7A31ul3lXjn35RTG0dlBUHv1Fn1d7T6je2QSq83D1da+dUZAo3czDy4hhIlJ1W4upGpXcOc87P4Azv+uDjgw5AI4uKQ/nnQfHN0sF59Id+cczM/QqtfJExqNVc9kM/bFFUWK1t/jNjUfqRBmFRsKm4fBgupqEgWI/Q9OzjfcTpKo9XBwhTrDwf7h6GSJ0erAF/MqwdGZan9eIUxMEqkQj4q/CzvfVb98j88GJUVd71Ya2n4PtYZYNj6RPc/y8ORMGHJRvVadVu0bFw5bRsKCanB2Sc6jSQmRT1K1mwup2i1Ckh7Ake9g/2TDoeycPODxd6D+KHAqZqnoREFEnoXd78OFFYbrq/WDLossE5MwO2m1K4S57P4ADk1Nv2/vBHVfhUbvSZ9PW+VdFbovh7D9sOtduL5NXV+1r2XjEoWKJFIh0jQYo3arSEmE6gOg2SS1qlDYPv9G0GsLXNsMF1dmHtf3/i31+qrUOIgCkEQqiqaUJLXrRInH0td5lIH2c6B0vexnMxG2S6eDoA7qLSNFgQ2DIPI0dPwJyrfJcnchsiONjUTRc+sE/NoElrVVB03PqPqLkkSLmtM/q3PCRl+F39vC369CYmyuuwmRRhKpKDpSkmDfp7CoAUQcVruybH/T0lEJSyvzhDqpeJpjM2BhLQjZZrmYhE2RRCqKhrSz0N0fQOrDvoTe1dWh/ETRVrwi9N4Gbb4Fh4d9guXsVOSDJFJRuD16Fgpq38JG78KLh8DvccvGJ6yDzg7qvw4Dj8vZqcg3SaSi8Io8nfVZ6Av7oMVkw2H+iqhUJZXElERSZYACVU5npxHHLBqasF7SalcUTglRsOQJdZQiUM84Hn8Hmk4otAlUURR0Op3+/oOkB3y661PCYsIIjQ1V/8aEEpcUR1JKEsmpySgP5/hc2WclT1d9Wr/v2dtn6bioI/7F/AnwCEj/65F+39/DHx83H+weHTTe1qWdnVboAhtfgv92qv1OS9exdGTCSkkiFYWTsxc0/wS2vKqehXZaUKiqce8+uMuhsEMcCj2k/g07xHPVnmNK+yn6bZzsnZj8z+Q8nW062Bl+FdyIvkFIVAghUSE57udk78TpkaepWLIQThmXdnZ6fLY6q48Q2ZBEKgqvOiPUTvZV+tj0wPJZJc3Ldy9n2i40NtTgvr2dPb7uvoTFhgHgaOeIXzE/vFy8cLRzxMHOAUd7R+x19pRyK2Ww7/2k+5RyK8Wt+7dyjM3BzoGg4kEG6z7b9Rkrz66kgX8D9RbQgFqla+Fo71iAo7cwnZ06CP6jrv0NMdeh5mDzxySsjiRSUThEh6hfbrVeSl+n0xWKL7oXVrzAhosbctzG1cEVDyePTOv/6P0HxZyK4V/MH2837zxXw3ar0o2ItyNITEnkZuxNQmNCCYsN01cPh8WGERYbRgmXEtjb2Rvsu+f6Hg6GHuRg6EH9Ok9nTzpV6kT3yt3p/FhnSrqWzFMcVunuRfizt3rZ4NZxaPUl2MlXaVEmr76wfTd2w5qecD9CncS5Ug9LR5RvyanJ7Lm+h78u/MXHbT82qGrtVrmbQSJ1dXClnn89gzO+qj5VM1XPAjQr18youJzsnSjnVY5yXuXyvE9cUhw6dPrrrwDRCdEsO7WMZaeWYa+z54nyTzC6yWh6VLW914oLK9KvvR+eDpGnoOtScClh0bCE5UgiFbbtxDz4e0R6q9w9E6Fit/Tps6zYg6QH/Hn+T9acX8P6C+u58+AOAJ0f60zLwPQuGN2rdOfMrTM0DGiYY9K0FtsGbiMmIYaj4Uc5GHqQ/aH72XhxI3cfJp8UJYUd13bwQq0XMu37aIMpq9ToHTVpbnlVfd9d2wyLG8HTa8C7mqWjExYg06jlQqZRs1KpyeqoREe+TV9Xvh10XQZWXm148c5FZh2cxU9HftInl4zGNBnD1x2/tkBk2klOTWZ3yG7Wnl/L6nOruXjnIjfG3CDAI0C/zfGbx+m/sj8jG46kX+1+FLP2AeT/26XWhDy4rd538oCnfoMKT1k2LpGJ1t/jkkhzIYnUCiXGwOqeEPJ3+rp6b0Drr636WtVfF/7im3+/YeOljZkeK1TXEHOhKApX710luESwwfoRf45g1qFZAHg4eTCwzkBGPD6C6qWqWyLMvIm+Bqu6q9dKAdBBq6+g4RiLhiUMSSK1MEmkVib+HqzoDGH71Pt2jtBuBtR+2aJh5cWAlQP45fgv+vtO9k70qdGH/rX70yqoFU72ThaMzrIURaHjoo5svrw502Otg1ozsuFInq76tHW2/E2MVWePubA8fV2zj6DphxYLSRiSRGphkkityINI+KND+lB/LiWgxxoo+4Rl48rC2dtnqexd2aCV7L7/9tF0XlOCigcxouEIBtcdTCn3Ujk8S9FzOOwwMw/MZPGJxTxIfmDwmH8xf4Y3HM6oJqPwdLayz6KSql6f3/cxoFP7LdcYYOGgRBpJpBYmidSK3DwCy1pDYjS4loJef0Op2paOysC1e9cYv308vxz7hcU9F9O3Vl/9Y4qisP3qdloGtszUZUQYuhd/j4VHFzLj4AzOR543eGx+j/kMqjvIMoHl5tA0cHSH2q9YOhKRgSRSC5NEamVu7IaNg6HHaqtqIXkr7haf7fqMGQdnkJiSCECFEhU48+qZIl1layxFUdh6ZSszDs5g9dnVVPauzPERx6261bKwPlp/j8u7UdiWMs1h0GmraVQUkxDDtH3T+GrPV8QkxujXl3ApwfAGw5HfqcbR6XS0q9COdhXacfnuZW7F3cqURD/Y+gGPBzxO9yrdrbPrzJnf1Gv6baarg4SIQsc6vo2EyMqDSDizGOq9bvgFZAVJNDElkR8P/sjHOz82GEbP1cGVUU1G8U7zdyjuUtxyARZCFUpUoEKJCgbrjoQd4dNdnwLq4BOft/ucFoEtLBFe1k4uUAe+R1EbxrX6UpJpIWT5byQhshJ/D/5oDxFHIOoKtJ5qNV9AkfcjaTqvKRfuXNCvs9fZM7T+UMa3Go+/h78FoytaFp9YrF/ec30PLRe0pHeN3nzf+XvraMiV8Vr4oa/B0RWaf2y5eIQmrH/4F1H0JMbAik5qEgU4t1Qd/s9KeLt5U8cvfUqtPjX6cObVM8zsOlOSqJl92f5LVvZZSTWf9Ovly04to8aMGvxx+g8LRvZQ9f7Q/sf0+/s+UW+iUJHGRrmQxkZmlpKkJtGQrep911LQZ4dVNSwCiIiL4OU1LzOh1QQaBDSwdDhFXkpqCguPLeTtzW/rh1oErOfs9PB3sO2N9PvtfoC6Iy0XTxEjrXYtTBKpmf39KhyboS67lFTng7RgF5f7Sfd5f8v7PFH+CZ6t/qzF4hB5Ex4bzoh1I1h1dpV+XSm3UuwYtINqpSz8Y+zAV7DzbXVZZw/PbYbybSwbUxGh9fe4VO0K63Hsx/Qkau8Ez/xp0ST6T8g/1JlVh+n/TmfEuhHcist5bk5heX7F/FjRewW/9vxVP8xicIlgHvN+zMKRAY+/BQ3fUpeVFFjbC+5lnldW2B5JpMI6/LcTtr6Wfr/9bAhoapFQklKSeHPjm7Sc35KLdy4CEJMYw/4b+y0Sj8gfnU5H31p9OTXyFL1r9GZ+j/nW0++0xecQ3Fldjo+ENc9CaoplYxJGk0QqLC/q6sMvlGT1foMxUGOgRUK5ff82HRZ1YOq+qfr5NJuWbcrRYUd5qrLM6mFL/Ir5sfS5pZkGvb8QeYEvd39pmT6+dvbqDDElqqhDXLb6yrBlr7BJVvIzTRRpSXHqsGoPbkNgB2g5xSJhnLh5gu5LunP13lVAHVT+s7afMarJKBnSr5CIio+ix5IenLl9hkNhh/ipx0+4ObqZNwhnL3hmrTpnbvGK5i1baEISqbA8nxrQ7wDsfEftL2qBarhVZ1fx4ooXiUuKA9SzmZV9VtKkbBOzxyK0s+nSJs7cPgPA0lNLuXDnAqv6rKKcVznzBlLCCq7ZCpORql1hHdxKQaf5anWXmd2+f5sBKwfok2gD/wYcGHpAkmgh1KtGL1Y/v1o/afjhsMM0nNOQPdf3WDYwRYEDX6oTMwibI4lUWMbNQ2qfUSvg4+bDwqcXAtC3Zl92Dd5FWc+yFo5KaKV7le7sG7JPP9xgRFwErRe05qcjP1kmoKQHsL6fWiOzugfE3bRMHKLAJJEK87t1HJa0hOUd4P5tS0cDwDPVnuGfwf+wuOdiXB1dLR2O0FiN0jXY//J+2gSp/TiTUpMYsmYI//vrf6SYuxWtzk4dBhMg5jqs6QkPZxAStkESqTCv5AT113fyfbi+HfZ/bvYQLt25xIwDMzKtb16+uXXOHiI04e3mzcYXN/La4+ndrr7d/y0vrnzRvMnUwRm6r4BiZdT7oXvg38nmK18YTRKpMK9/P4HbJ9XlUnXMPoD3udvnaLmgJa+uf5Vpe6eZtWxhfRztHfmuy3fM7jpb39e0vGd57HRm/mos5g89VqojHoH6OYk4at4YRIFJIhXmc/NQ+i9tOwfotECdDcNMTkacpNWCVoTGhALw09GfiE+ON1v5wnoNbTCUFb1X8FbTt/j8yc8tUzPh9zg0fk9dTk2GDYOkitdGSCIV5pGcoH4xKA+rzBp/AKXrmq34EzdP0HpBa24+bMhR168u2wZuw8XBxWwxCOvWrUo3vuzwpWWr95t8AD611OVbx6SK10ZIIhXmse/jDFW6ddN/eZvB2dtnefKXJ4l8EAlAozKN2DpgKz5uPmaLQdimff/tY8DKASSa68zQ3kmtqZEqXpsiiVRo7+ah9EZFdg5qf1F7R7MUfenOJdr93I6IOHU+00ZlGrG5/2ZKuJq/v6qwLbuu7aL9L+355fgv9FvRj+S0ISy15lvfsIp31zjzlCsKTBKp0JYFq3RDokJo+3Nb/TXRen712NBvA57OMh2eyF1yarI+ef5x+g8GrRpEqpJqnsLTqnirvQhdFpunTFFgkkiFtlKTwPdxddmMVbqKotDr916ERIUAULN0TTb13yRnoiLP2gS3YWWflTjZOwGw+MRixm8bb57C7Z2g727o8gs8nA5OWC+bS6QzZswgODgYFxcXGjRowK5du7Lddvv27eh0uky3s2fPmjHiIs6pGHT6CZ5Zp177MVOVrk6n47vO3+FfzJ9KJSvxd/+/5ZqoyLdOlTqx7Lll+u4wn+76lKUnl5qncCcP85QjjGZTiXTp0qWMGjWK999/nyNHjtCiRQs6d+5MSEhIjvudO3eOsLAw/e2xx2TAaLOr0AVK1zFrkY3KNOLgKwdZ/8J6fIv5mrVsUXj0qNqDr9p/pb8/ePVgDocdNn8gsWFwbpn5yxW50ikWmZSvYBo3bkz9+vWZOXOmfl21atV4+umnmTw5czPx7du306ZNG+7evUvx4sULVGZ0dDReXl5ERUXh6SnX1vJMUUBGCRKFhKIovLTmJRYcXQBAWc+yHBx60Hw/0M78qk58nxQHL50Hz0DzlFtIaP09bjNnpImJiRw6dIgOHToYrO/QoQN79uQ8c0O9evXw9/enXbt2bNu2LcdtExISiI6ONriJfEqIhkUN4cRP6ZN1m8HR8KO8t+U984+VKgo9nU7HrKdm0bRsUwD+i/6Pnst6mq8lb8RRiL+rDtCwZ6J5yhR5ZjOJ9Pbt26SkpODra/gL0NfXl/Dw8Cz38ff3Z/bs2SxfvpwVK1ZQpUoV2rVrx86dO7MtZ/LkyXh5eelv5cqZeZ7CwuDg1xBxGDYNgZ3vmqXIiLgIeizpweR/JtN9SXeiE+QHkDAtZwdnVvRZQVnPsjjYOTCg9gD9sIKaazwOnIury6d/htunzFOuyBObm9j70VFHFEXJdiSSKlWqUKVKFf39pk2bcv36db766itatmyZ5T7jxo1jzJgx+vvR0dGSTPMj7iYc+lpdtnOAuiM0LzIxJZHnlj2nb6F7+/5tfUtLIUzJr5gfq/qsIi4pjpaBWX+HaMKlBDQaB7vGgpIK/7wHT682X/kiRzZzRurj44O9vX2ms8+IiIhMZ6k5adKkCRcuXMj2cWdnZzw9PQ1uIh/+/VS9jgNQexgUr6h5kW9ufJNdIWrr7QCPAFb2WSlD/wnNNAhoYN4kmqbea1AsQF2+tAZuWHgycqFnM4nUycmJBg0asHnzZoP1mzdvplmzZnl+niNHjuDv72/q8ATAvctwbJa67OCmdirX2NYrW/n+wPcAONs7s6rPKgI8AjQvV4iM9t/YT2xirLaFOLpB04np93e9qzbqExZnM4kUYMyYMcydO5effvqJM2fOMHr0aEJCQhg+fDigVssOGDBAv/306dNZtWoVFy5c4NSpU4wbN47ly5fz2muvZVeEMMae8eoADAANx4C7n6bFxSTE8NLql/T3v+7wNY+XeVzTMoXI6EHSA97e9DZN5zVl3N9mGMqv5mAoUVldvrELrvylfZkiVzZ1jbRPnz5ERkby0UcfERYWRs2aNVm/fj2BgWpT8LCwMIM+pYmJibz11lvcuHEDV1dXatSowbp16+jSpYulDqHwijimNtEHcPGGhm9pXuTYv8dyLeoaAK2DWjPice2vxwqRUWhMKD8c+IFUJZXvD3zPs9WfpXVQa+0KtHOAJz6Ftb3U+/+Mg+BOYO75U4UBm+pHagnSjzSPVjwFV9ary62+Vs9INbT1ylba/dwOAHdHd06MOEFwiWBNyxQiK9/s+4ZRG0cBEFw8mBMjTuDu5K5dgYoCvzaG8ANqI6Tnd4N3Ne3KKwSkH6mwfv/tTE+iHuWg7kjNi5z8T/oAHFOenCJJVFjM641fp0X5FgBcuXeFd//WuMuXTgctv1Bb8Q65LEnUCkgiFcYrXglqDVXnUGz2EZihxeyqPqt4o9EbtA1uK1W6wqLsdHb81OMnXB1cAfj+wPdsv7pd20LLtYYWn4FLcW3LEXkiVbu5kKrdfLh7AbwqgJ292YpMSknC0UwD4QuRE7NX8Yo8k6pdYTtKPGbWJApIEhVW49Eq3ve2mGfKQEAdljP6mvnKEwYkkQqbsfHiRv0k3aLoSElV2HspktVHb7D3UiQpqdZZifZoFe+MgzO4eOeitoXG34O/R8KPZWDr/7QtS2Qr391f7O3tCQsLo3Tp0gbrIyMjKV26NCkpMmB4kXHmV0iKhaovqPOOaujug7s8v/x5EpITGNN0DB+3+TjboSFF4bHhZBiT1p4mLCpev87fy4UJ3arTqab1DaxSqWQl3mn+DpN2TKKqT1XuPrirbYFOxeDSavVzeHktRIeAZ3ltyxSZ5PuMNLtLqgkJCTg5yfimRYaSCrs/hM3DYHZZeHBH0+I+/+dz7sXf40HyA8JiwiSJFgEbToYxYtFhgyQKEB4Vz4hFh9lwMsxCkeXszaZvsuiZRRwddlT7AULsHNShOEH9TB6frW15Ikt5PiP99ttvAXXQ+Llz51KsWPoZSEpKCjt37qRq1aqmj1BYp6ubIOqyuuzXCFxLalbUf9H/8e1+9f3nbO/MxNYTNStLWIeUVIVJa0+T1c92BdABk9aepn11P+ztrOtHlYezB/1q9zNfgbWGwr6P1SkLT8yBpuNBJm0wqzwn0mnTpgHqGemsWbOwt09vVOLk5ERQUBCzZs0yfYTCOh1Ln1ydOtr2G/1ox0fEJ6tnJa81eo1yXjIbT2G3/8qdTGeiGSlAWFQ8+6/coWlFb/MFZo2K+UOlnnB+GdyPgAsroOrzlo6qSMlzIr1y5QoAbdq0YeXKlRQvXlyrmIS1i74Gl/9Ul4uVhYpdNSvq3O1z/HTkJwA8nT0Z94QZxjMVFhcRk30SLch2lnTgxgF+Of4L33T6RrtLEnVHqokU4OgMSaRmlq9rpElJSVy7do3QUGk5WaQdn61ejwGoM0y9TqOR97e+T4qiNmB7p9k7eLsV8bOPIqK0R94G9cjrdpby3pb3aDS3Ed/t/44VZ1ZoV1DZluBdXV2+sQtundCuLJFJvhKpo6MjCQkJ0tCjKEtOgBNz1WU7B6j1smZFHbhxgOVnlgPg6+7LqCajNCtLWJdGwSXx93Ihu28aHWrr3UbB2l2bN4Xm5Zrrl9/f+j7JqcnaFKTTGV5iyXjpRWgu3612X3/9daZMmUJyskZvCGHdLqxQr8MAPPasplOlfbTzI/3y+FbjZZSYIsTeTseEbuoZ1qPJNO3+hG7Vra6h0aO6PNaFJ8o/AcC5yHMsO7VMu8Kq9wfHh5+R07+ogzQIs8h3ndy///7Lli1b2LRpE7Vq1cLd3fDLbcUKDasvhOWd/TV9uY52Y9xGJ0SzO2Q3AOU8y/Fyfe3OfIV16lTTn5kv1s/Uj9TPivuRPkqn0/Fxm49ps7ANAD8c+IEXar2gTWHOnlDtRbVqt2J3SEnQphyRSb4TafHixXn22We1iEVYu6QHEPK3uuzuD2VbaFaUp7MnIaND+O3EbzjZO+EkzfmLpE41/Wlf3Y/9V+4QERNPaQ+1Otfaz0QzahXYipqla3Iy4iR7ru/haPhR6vrV1aawtt+BDJtpdjJofS5k0PpH3L2ojqAC0GC0ZWMRwkbMPDCTkevVa5iv1H+FH7v9aOGIihatv8clkeZCEqkQwlgxCTEETA0gNjEWN0c3QseE4uXiZemwigyrnP3ljz/+oHfv3jRp0oT69esb3IQwVlR8lKVDKPJsZaB4W+Hh7MGA2gMAuJ90n5+P/ax9ofcuwfXt2pcj8p9Iv/32WwYPHkzp0qU5cuQIjRo1wtvbm8uXL9O5c2ctYhRFyJGwI/h97cegVYM4Fn7M0uEUSRtOhvHElK30nbOP/y05St85+3hiylarHdvWVmScgH7z5c3aFZSaAj/XhXmVYONLIJWOmst3Ip0xYwazZ8/m+++/x8nJiXfeeYfNmzfzxhtvEBUlZxKF1pEfYNd7ELovfTAGDcw8OJP45HgWHlvI3v/2alaOyJqtDhRvC2qWrskHLT7g7/5/s/r51doVZGcPrqXU5agrEHlKu7IEUIBEGhISQrNmzQBwdXUlJiYGgP79+/Pbb7+ZNjphPY7NhP2T4bdmcP+WJkXci7/H4hOLAfBw8qBfLTMO/C1yHSge1IHipZq34D5u+zHtKrTTflCbit3Tly+t0bYskf9E6ufnR2RkJACBgYHs27cPUMfilXZLhdS9y+m/av2bgLuvJsX8fup37ifdB2BAnQF4OHtoUo7IWn4GihdWrmK39GVJpJrLdyJt27Yta9eq3R+GDBnC6NGjad++PX369OGZZ54xeYDCCqR1dwHDX7omtuZ8+gd+YJ2BmpUjslaYBoq3FZqdfHgFQana6nLYvxAXrk05AijAgAyzZ88mNVW9RjZ8+HBKlizJP//8Q7du3Rg+fLjJAxRWIOMv2kraJNK4xDj+vqwO9hDgEUCDgAaalCOyV1gGird2D5IeMPfwXNacX4NfMT9+eeYXbQqq2B1uHVeXL/0JtWV0MK3kK5H++++/rFmzhqSkJJ588kk6dOhA79696d27t1bxCUtLjIH/dqrLXhWgZDVNivn78t/6OUe7Ve6Gna5APbOEEdIGig+Pis/yOqkOdXg+ax8o3to52jsyYfsE7sbfxdPZk8SURG1G7qrQDfZ9oi5fWSeJVEN5/rZauXIlzZs355tvvmH27Nl07tyZ6dOnaxiasAo3D0PajBWB7dVZJjSw5lz6WW/3KtpVH4vsFZaB4q2dg50DT1V+ClDHlN55bac2Bfk1BOfi6nLYv9qUIYB8JNLPPvuMQYMGce/ePe7du8ekSZP45JNPtIxNWIObh9KXfRtqUkSqksqfF9SJwt0c3Wgb3FaTckTu0gaK9/MyrL7183Jh5ov1bWKgeFvQrXJ6Y6CMPyJNSmcHvg8HyYkLg1iZR1orea7aPXfuHIsXL8bBQd3l7bffZuLEidy+fRsfHx/NAhQWdvNg+rKfNon0v+j/cHVwBaBDxQ64OMg1OEsqDAPFW7uOFTviaOdIUmoSa8+v5ZtO32jTJaZ0A/XHcOn6kBAFxQJMX4bIeyKNjY2lePHi+vvOzs64uroSHR0tibQwSzsjtXcG7xqaFFHeqzxX/neFExEnSNVwsAeRd/Z2OppW9LZ0GIWWl4sXrYNas/nyZq7eu8rJiJPU8q1l+oKaTYKWUzS7JCNU+WpstHHjRry80gdaTk1NZcuWLZw8eVK/rnt3ub5VqDR+D8IPQvIDTadn0ul01PatrdnzC3XABTnLtB7dq3TXDxW45twabRKpo6vpn1NkkufZX+zscr+cqtPpSElJMTooayKzv4jCYMPJsEwTZPvb0ATZhdG1e9cI+iYIgCZlm7B3iAyJqRWrmf0lNTU111thS6JCFAYyfq51CiweSBXvKgAcDjtMYkqitgUqijqgvTA56awnLOqjHR/RakEr3tz4JqEx0qrQ1GT8XOuWNvBIYkoipyI0Glz+yl/we3uY4QNX1mtTRhEniVRk79oWzYcW23FtBzuv7WTqvqkyCIMGZPxc6zaswTB+7fkr5147Rx2/OtoUkhANIX9D/B3D7mzCZPI9RKAoIhKi4Y8n1eXgLtBzncmLUBSFQ6HqBzvAIwC/Yn4mL6Ook/FzrVvLwJbaF5Kx25okUk3IKYDIWsSR9GXP8poUcenuJaIS1DlsG/jL2LpakPFzBV4V0kc4kkSqCUmkImu3jqYvl9YmyaWdjYIkUq2kjZ+bXScXHWrrXRk/txDT6QxHOLofYdl4CqF8J9JBgwaxc6dGY0MK6xF9PX25xGOaFHEoLEMildleNFGUx89NSVXYeymS1UdvsPdSpNU2qAqPDWfFmRW8v+V9LkRe0KaQ4hk+wzHXs99OFEi+r5HGxMTQoUMHypUrx+DBgxk4cCBlypTRIjZhSXEZukS4a9PP0CCRyhmpZtLGz320H6lfIe5Hakv9Zn898StvbnoTgOASwTzmrcEP14yf4dgw8DV9EUVZvs9Ily9fzo0bN3jttdf4/fffCQoKonPnzvzxxx8kJSVpEaOwhLgMXVGKmf6L59GGRv4e1vXlVth0qunPP2Pb8tvQJnzzfF1+G9qEf8a2tbqkYgq21m8244/IjJc7TCrjGLtx0s3M1Ap0jdTb25v//e9/HDlyhP3791OpUiX69+9PQEAAo0eP5sIFjaonhPnEPvyycSwGTh4mf/qw2DB9Q6O6fnVN/vwis7Txc3vULUPTit6FtjrX1vrN1vOvp18+dUujvqSPnpEKkzKqsVFYWBibNm1i06ZN2Nvb06VLF06dOkX16tWZNm2aqWIUlpBWtavRbBEZB18or1GrYFH02GK/WU9nT7yc1THMw7RKcgZnpJJITS3f10iTkpJYs2YN8+fPZ9OmTdSuXZvRo0fTr18/PDzUM5clS5YwYsQIRo8ebfKAhRkkxUFitLqs0fXR8l7lmdd9HmExYQa/yIUwhjX0my3I5AD+Hv5EJUQRFhOGoiimn1LNqwK0+lr9PPvUNO1zi/wnUn9/f1JTU+nbty/79++nbt26mbbp2LGjwZRrwsbE3Uxf1uiMtLR7aV6q95Imzy2KLkv3my1oI6cAjwDO3j5LXFIcMYkxeDqbeGB1l+LQcIxpn1Po5TuRTp06ld69e+Pikv0bsUSJEly5csWowIQFFa8A/4uH+9oODyiEqaX1mw2Pis/yOqkOtbWyFv1m0xo5PVpuWiOnmS/WzzaZ+mdo0BcWE2b6RCo0la9rpMnJybz00ktcvHhRq3iEtXBwBs9A9SaEjbBUv1ljGzllTKQyeYPtyVcidXBwIDAwUKZLE0Y7cfME526fIzohmjxOiStEnqT1m/XzMqw18/NyyfGs0BjGNnIK8Ei/hJKfBkf5GnTiwR2IOKrOBpMUl+cyRO7yXbX7wQcfMG7cOBYtWkTJkjKsmCiYwasHcyjsEHY6OxI/SMReZ2/pkEQh0qmmP+2r++W70U9BGdvIKbB4IMHFgwnwCKCYU7E8PVe+r8fuehdOzFGXXzwMvtLIz1TynUi//fZbLl68SEBAAIGBgbi7uxs8fvjwYZMFJyzkxDyIvqq28Ks+APL4wc6PtOorX3df7O0kiQrTS+s3aw7GNnLqWa0nPav1zHN5Bboem7EFflwYIInUVPKdSJ9++mkNwhBW5cp6uLBCXa7Yw+SJNCU1hZsPWwZnrNISwlaZs5FTbtdjdajXY9tX9zM4A091LKa/lrf64EV8Um/TpELhHJjD3PKdSCdMmKBFHMKapCanL9uZfsra+0n3SVVSASjuUtzkz2+LCtL30JzPZ6zs4rG2OHOKNSdpjZxGLDqMDgySXFaNnHIqI7fHFuy+kufrsWln5BtOhnF880XeeXhCvPnUDf48/C/ujvB1H22uGxclNjex94wZM/jyyy8JCwujRo0aTJ8+nRYtWmS7/Y4dOxgzZgynTp0iICCAd955h+HDh5sxYhtkkEgdTf70yRme39He9M9va0w9wLq1DdieXTzd6/iz5liY1cQJxv3v8jo5QE5lAPl6LCdp12M3nAxj+KLD9Hexg4eJ1AG1wWhcEgxfdJhZGjXCKirynUhTUlKYNm0ay5YtIyQkhMTERIPH79zRbuitpUuXMmrUKGbMmEHz5s358ccf6dy5M6dPn6Z8+czDzF25coUuXbowdOhQFi1axO7duxk5ciSlSpXi2Wef1SxOm6fxGalBItUgUdsSY/oemuP5jJVdPGFR8fy4M3Nfc0vFCab53+XWyCm7MkKjonl6WUcgBSelAiVJ/7EfHhXP8EX5b3tS2sOFlFSFN5YcASCF9LYIaYk0zYhFh7n4WReL1wbYqnyPtTtp0iT9oAxRUVGMGTOGnj17Ymdnx8SJEzUIMd3UqVMZMmQIL7/8MtWqVWP69OmUK1eOmTNnZrn9rFmzKF++PNOnT6datWq8/PLLvPTSS3z11VeaxmnzUjPM4qNBIk3K8PwOGjy/rTD1AOvWNmB7TvFkx1IDy5vyf5fd5AA5/z90JNifIMH+NIm6q1mWn1cZJ2v/59wtEpPVZ0jOkEjtdYaJVAG2npQBWAoq34l08eLFzJkzh7feegsHBwf69u3L3LlzGT9+PPv27dMiRgASExM5dOgQHTp0MFjfoUMH9uzZk+U+e/fuzbR9x44dOXjwYLZTviUkJBAdHW1wK3LMeEZalBOpqQdYt7YB23OLJzuWGFjeHP+7nMvI+FVsfD/9tOuxs/+5rF+XrKQnUscsyvjgT41mnikC8p1Iw8PDqVWrFgDFihUjKkqdCqtr166sW7fOtNFlcPv2bVJSUvD1NZyR1tfXl/DwrH9JhYeHZ7l9cnIyt2/fznKfyZMn4+Xlpb+VK1fONAdgS0w9YPajT59pzJmiydQDrFvDgO2mLMdcceanLGNiyvu+Bf982OnglZbB+iro0KgHWT5rVme5sQnJWawVeZHvRFq2bFnCwtSRNypVqsSmTZsAOHDgAM7OzqaNLguPzoqQ20wJWW2f1fo048aNIyoqSn+7fv26kRHboIxniammn6w941loxrPTosbUA6xbesB2U5djrjjzU5YxMeW8b8YzxILPbqkoMHvnFf3k5QFervrHMlbnZqzmTRPgZb7/d2GT73q1Z555hi1bttC4cWP+97//0bdvX+bNm0dISIim06b5+Phgb2+f6ewzIiIi01lnGj8/vyy3d3BwwNs7647azs7OZvlBYNUyNgDSINGVci/Fhdcv4GDnkOdRXAojU/c9tOSA7QWJJzvmjhPM87/LqQwlQyLVZZHk8urRfqSvPFGB3ZciAVge3451CU9gTyoJilOmfZe+0qzA5RZ1+f7p8/nnn/Pee+8B8Nxzz7Fr1y5GjBjB77//zueff27yANM4OTnRoEEDNm/ebLB+8+bNNGuW9RugadOmmbbftGkTDRs2xNGxaLcWzVGJKuD3OPg31eTpHewcqFSyEkHFg/Bx89GkDFtg6gHWLTVge0HiyY4l4gTT/u+yG/825/9HxjNSw0Sqy2Y5Oxmv5z5RpRRODnYPS7AnTnEjWilGAoaJtFQxJ0oWy5xcRd7oFBsaMXzp0qX079+fWbNm0bRpU2bPns2cOXM4deoUgYGBjBs3jhs3bvDzzz8DaveXmjVrMmzYMIYOHcrevXsZPnw4v/32W567v0RHR+Pl5UVUVBSenjK1kTA96UdqHXGC8f+7vOyf1TY+nvEcSnoOgOK6xnjd/zDT/pC/fqTfPF+XHnXL6PuRZsfTxYHjEzvm6Tltldbf4wVKpOfPn2f79u1ERESQmppq8Nj48eNNFlxWZsyYwRdffEFYWBg1a9Zk2rRptGzZEoBBgwZx9epVtm/frt9+x44djB49Wj8gw9ixY/M1IIMkUmEOMrKRdcSZU6y5ya6PaNqeGfuhPlqGR7Gb1JpVA4AXa/VnZJ1pOY5s9PG6M7nG89vQJgYjG41fdYKI2PQ2D3bAFz1r8lyjwj9VotUl0jlz5jBixAh8fHzw8/MzaLSj0+kK3aD1kki1se78Oi7cucC9+HtMbD3R0uEIYZSUVIUnpmzN9mwx7RrrP2PbZpmUt1zewpO/PAnAO83eYUr7KbmWldv13EfLSjn7O+HndnJH501Cxd7Uq1bN4j9azEXr7/F8Nzb65JNP+PTTTxk7dqzJgxFFx8c7P+bfG/8C8H6L92WoQGHT8tMPNasZaSqUqMCX7b8kNCaU1kGtcywrv+P66ve7+hdlLs6nDEDTZ9W+MsIk8p1I7969S69evbSIRViLq5vgwBSIDYNmE6FKb5MX4e+Rfr3pZtxNynqWNXkZomgzZ7Wxsf1Qg0sE81azt/JcXl7H9TUQl2HC8GIy65Ip5TuR9urVi02bNsnA74VZYjSEbFWX713OedsC8i+W/kEPjQmVRCpMytwNrizRhzffk5fHqXMAY+8ELubrWlQU5DuRVqpUiQ8//JB9+/ZRq1atTN1I3njjDZMFJyzEPcOv1Yy/Yk0o4zykYTHalCGKJksM3G+pPrz5mrw89uHnzM1P89HLipp8J9LZs2dTrFgxduzYwY4dOwwe0+l0kkgLgwxni/pfsSaW8Yw0LFYSqTCNgk56bayCXrdMc+nOJTydPfF288ZOV/CRjbKVkgQPbqnLUq1rcvlOpFeuZJ76SBQy7hkSqUZJLuMZaWiMNslaFD3GNvoxRoGuW6btu7gTF+9cxMfNh1tv3zJpXADEZRjhzV3mHTW1ojv1hsiegwu4lID4u5pV7WZsbCRVu8JULD1wf76vWz6U9hnQbKQvaWikqTwl0jFjxvDxxx/j7u7OmDFjctx26tSpJglMWJh7wMNEGqqOhG3iayplPMrol6/ck1oOYRrWMHB/vq5bArfv3yYuKQ4wrKkxqdgMtT5yRmpyeUqkR44c0c/feeTIkWy3y2kWFmFj3P0h8hQkx0NCFLgUN+nT+7j54Ovuy824mxwOO5zrLD5C5IW1DdyfF4dCD+mXa5eurU0hckaqqTwl0m3btmW5LAqxjB+2uFCTJ1KdTkfTck25eu8qDfwb8CD5AW6ObiYtQxiyxuH4TM3YRj+WcCgsPZE2CGigTSHFykDF7mpC9aqgTRlFmFwjFVkzaHAUCt7VTV7Eit4r5CzUTKxtIHstGdPoxxIMEqm/Rom0Unf1JjRRoPlIs/ry0+l0uLi4UKlSJV544QWqVKlikgCFhZRpDspb4NsAStfTpAhJouZhiX6VllbQRj+WkFa16+7oTmXvyhaORhREvjsseXl5sXXrVg4fPqz/Ijxy5Ahbt24lOTmZpUuXUqdOHXbv3m3yYIUZVewGrb6Eqs+Dq2m7CQjzya1fJaj9KtPmzCxM0hr99KhbhqYVva0yid6+f5trUdcAqO9fH3u7gk/qLSwn34nUz8+PF154gcuXL7N8+XJWrFjBpUuXePHFF6lYsSJnzpxh4MCBMqi9yJd78fewoalxbUZ++lUK88vY0Eizat2k++pNaCbfiXTevHmMGjUKO7v0Xe3s7Hj99deZPXs2Op2O1157jZMnT5o0UFE4TflnChW/rUiJKSW4eu+qpcMpdCzdr1LkLDQmFBcHtSuOZg2Nzv8B33nAwlpweZ02ZRRx+U6kycnJnD17NtP6s2fPkpKSAoCLi4tc/yoMFAWirsL55epfDcQlxXH5rjowfsZGF8I0rKFfpcje4HqDiRkXw7Hhx+jyWBdtCrl5CJRUuH0S7Jy0KaOIy3ci7d+/P0OGDGHatGn8888/7N69m2nTpjFkyBAGDBgAwI4dO6hRo4bJgxVmdmIOzA2Gtc9p9ks2Y3XWgRsHNCmjKEvrV5ndz1odautda+pXWdQ42DlQ27c2JV01eg1uZviB6qvRWW8Rl+9Wu9OmTcPX15cvvviCmzdvAuDr68vo0aP110U7dOhAp06dTBupML9SddKXbx7UpIgmZZvolzdc2sCU9lM0KaeossV+lcKEUlMg4uEgOl7BoFWyLuLyfUZqb2/P+++/T1hYGPfu3ePevXuEhYXx3nvvYW+vtjgrX748ZcvK/JI2z6c26B62IrypTbWrbzFfGpdpDMDxm8flOqkG0vpV+nkZVt/6ebkUyq4vtiJVSdW+kDtnIflhQyM5G9WMUQMyeHp6mioOYY0cXcGnBtw6DpGnIemBus7Eulfpzr83/gVg7bm1vN74dZOXUdTZUr/KoqLtwrY42TvRrXI3Xm30qjbTp2X8AVxaEqlWCpRI//jjD5YtW0ZISAiJiYkGjx0+fNgkgQkr4dtQTaRKCtw6BgFNct8nn7pV7sb7W98HYM35NZJINZKfwdSLwnCClnQz9iY7r+1EQSEsNky797xcHzWLfP8E+vbbbxk8eDClS5fmyJEjNGrUCG9vby5fvkznzp21iFFYUsYPn0bVuzVL1ySoeBAA269uJyo+SpNyRN5sOBnGE1O20nfOPv635Ch95+zjiSlb2XBSprszlXUX1qE8vGLdvbKGQ/dJIjWLfCfSGTNmMHv2bL7//nucnJx455132Lx5M2+88QZRUfIFWOhk/PCF79ekCJ1Op/8ySU5NZsPFDZqUI3KXNpzgo4M4pA0nKMnUNNacW6Nf7l5Fo0SakiQNjcwk34k0JCSEZs2aAeDq6kpMTAygdov57bffTBudsLxSdcDh4XXRqxvV/mgaSPsyKeZUjJtxNzUpQ+SsKA8naE4Pkh6w+fJmAHzdfXm8zOPaFBR5Gnj4efVvqk0ZAijgEIGRkZEABAYGsm/fPgCuXLkiQ7wVRg4uENheXb5/E8K16evZMrAlG/pt4Pbbt3mj8RualCFyJsMJmsfWK1u5/3DIvq6Vu2rTyAigdB0YGQk9VkN9+UxpKd+vYNu2bVm7di0AQ4YMYfTo0bRv354+ffrwzDPPmDxAYQUqdgd7ZwjWaOQVwNHekY6VOuLs4KxZGSJnMpygeaw+t1q/rFm1bhpHN3X6NP/G2pZTxOW71e7s2bNJTVWrC4YPH07JkiX5559/6NatG8OHDzd5gMIKVO2rzgLj6G7pSISGZDhB7cUkxLDk5BIA3BzdeLLCkxaOSJhCvhOpnZ2dwYD1vXv3pnfv3iYNSlgZRzezFxkWE4aroyvFXYqbveyiKm04wfCo+Cyvk+pQB3GQ4QQLbvGJxcQkqu1K+tXqh5sFPlvC9ArUjzQ+Pp7jx48TERGhPztN0727zMIuCu585Hk+3PYhK86s4OM2H/PuE+9aOqQiQ4YT1N7lu5ex09mRqqQy8vGR2hW0vBM4F1cvy1TtCzKJiKZ0Sj5bCG3YsIEBAwZw+/btzE+m0+lngCksoqOj8fLyIioqSkZyArVJ/e0T4Ftfk6e/dOcSj333GAoKgV6BXHrjkkx2bGYbToYxae1pg4ZH/l4uTOhWXYYTNIHrUdf58/yfjHh8hDYFxIXDrABAAZ+aMPCENuXYEK2/x/OdSCtVqkTHjh0ZP348vr6+Jg/I2kgizWDH2+qMMElxMOIWaFTt2mVxF/66+BcAa/uupWvlrpqUI7InIxvZsBPzYNPL6nLj9+CJTy0bjxXQ+ns83612IyIiGDNmTJFIouIRqUmQEAWpyXBVu0ETMlZ5/XDgB83KEdlLG06wR90yNK3oLUnUllxam75cUS61mUO+E+lzzz3H9u3bNQhFWL2MH8qMH1YT61yps37IwA0XN3DpziXNyhLCHM7ePktiSmLuGxor6QFc26Quu/mCn0aDPQgD+W5s9P3339OrVy927dpFrVq1cHR0NHj8jTek42+hVaYFOHupZ6VX1qvXS+0dc98vn+zt7BneYDjvblEbGs06OIsvO3xp8nKEMIeU1BQ6/NKBxJREhjUYxsTWE9Fp1fgnZAskP1CXK3YDrQZ7EAbynUh//fVXNm7ciKurK9u3bzd4Q+h0OkmkhZm9ozoow9nfIOGemkwr9dCkqJfqvcT47eNJTElk3pF5jG81Hg9nD03KEtbN1q/Xrjq7iuvR1wE4FHZIuyQKcGZR+nKFbtqVIwzkO5F+8MEHfPTRR7z77rsG/UlFEVG9v5pIAY7N1CyRlnIvxfM1n+fnYz9zN/4uU/dOZULrCZqUJayXrbcgTklN4cNtH+rvv/r4q9oVFhcOF5ary66lIKijdmUJA/nOhImJifTp00eSaFEV1FGdSQLUQezvXtSsqA9bfoiDnfpb76u9X3H7fuYuV6LwKgwz0fx87GfO3D4DQLNyzehUqZN2hZ2YqzYEBKj1Mshwm2aT72w4cOBAli5dqkUswhbo7KBOhv5vx2ZpVlSlkpUYWn8oVbyrsPDphXi75m1SamH7CsNMNPHJ8UzYnl6L8nm7z7Wt1o08/XBBB3WGaVeOyCTfVbspKSl88cUXbNy4kdq1a2dqbDR16lSTBSesVI3BsPtDSEmAUz9B84/B0VWToqY8OQVXR1f9makoGvIzE03Titb5A2vGgRn6a6NdHutCi8AW2hb41K/QaBzc2AWegdqWJQzk+9vpxIkT1KtXD4CTJ08aPKbpry1hPdx8oEofCNkKtV8BJVmzoqSBUdFk6zPRRMVH8ekudSAEHTomt5tsnoJL1VJvwqzynUi3bdumRRzC1rSeBs6eYIEzxfjkeFwcZAaSwszWZ6L5as9X3Hmgztvar3Y/avvWtnBEQkvSYkgUjGtJsyfRo+FH6bK4C71+72XWcoX5pc1Ek10dlw619a41zkSTmJLIT0d/AsDRzpGPWn+kbYH3LkH+RnoVJpbnb8KePXvmabsVK1YUOBghspOcmkyPJT0IiQoBYNe1XdpfcxIWY8sz0TjZO3Fs+DEm75qMvZ09wSWCtSss6T4saqiOYtRgFNSROaEtIc9npF5eXnm6iSIo6grsGgcPIjUrwsHOgfEtx+vvj1g3goTkBM3KE5bXqaY/M1+sj5+XYfWtn5cLM1+sb9X9SH3cfPi649d80f4LbQs6u0QdHOXuOQjbp21ZIlv5nv2lqJHZX3JxfA5sHgYo0PJLePwtzYpKTk2m8dzGHA47DMC4J8bxWbvPNCtPWAdbH9lIM4qino1GqJ8HXvgX/BtZNiYrZXWzvwhhoGwr9BVvh6erg2ZrxMHOgQU9FuBop3a5mrJ7CgduHNCsPGEdbGUmmgVHF+gvPZjFtU3pSdS3gQxQb0GSSIVxSlaGig+HCYy9AUe+07S4Wr61GN9KreJNVVIZvHqwVPEKi9v33z6GrBlCzRk1+enIT9oXqKSql1PSNHwLpPuhxUgiFcZ74lP0TUD2T4b4u5oWN7b5WOr71wfg1K1TTNoxSdPyhMhJfHI8g1cPJlVJJSYxhpuxN7Uv9NwyiDiiLpeuB1V6a1+myJYkUmE8nxpQY4C6nHAPDmjbwMLR3lGqeIXVmLBtAmdvnwWgYUBD3m7+trYFpiTB7g/S77eYLNOlWZj894VpNJsE9k7q8uFvIDZU0+IereLdemWrpuUJkZV9/+3jq71fAWq3lwU9Fmg/nOWJuWrfUYBybSCwg7bliVzZTCK9e/cu/fv313ez6d+/P/fu3ctxn0GDBqHT6QxuTZo0MU/ARY1nINQZqS4nP4C92le3jm0+lp7VerJ1wFbGPjFW8/KEyOhB0gN9lS7AxFYTqVG6hraFpqbAgSnp91t8LtdGrYDNdH/p3Lkz//33H7NnzwbglVdeISgoiLVr12a7z6BBg7h58ybz58/Xr3NycqJkybyPhiLdX/Lh/m2YVwESY0BnD4NOq42RhChkFEWh34p+/HZSnZu3YUBD9g7Za57JFaKuwp7xkBwP3ZZpX14hoPX3uE1MqXHmzBk2bNjAvn37aNy4MQBz5syhadOmnDt3jipVqmS7r7OzM35+fuYKtWhz84GGb6sfcq9guB9hkUT6IOkBrhrNRiMEqNfl05Kou6M7C59eaL4ZiryCoPPP6tmpsAo2UbW7d+9evLy89EkUoEmTJnh5ebFnz54c992+fTulS5emcuXKDB06lIiICK3DLdoajIb2s9Wz0bJPmLVoRVH4cveX1J5VWyYBF5q5HnWd8dvSR9la1HMR1UtVN38gdvbmL1NkySYSaXh4OKVLl860vnTp0oSHh2e7X+fOnVm8eDFbt27l66+/5sCBA7Rt25aEhOz7HSYkJBAdHW1wE/ngVAxqDwV7x9y3NbFPdn7CO3+/w8U7F+n1ey+SUpLMHoMo/Mp5lWPDixso6VqST9p8wtNVn9a+0Ad31HF1hVWyaCKdOHFipsZAj94OHjwIZD3XqaIoOc6B2qdPH5566ilq1qxJt27d+Ouvvzh//jzr1q3Ldp/JkycbjB1crlw54w9UmMWguoPwdfcFYPvV7YzeONrCEYnCqm1wW06OOMl7Ld4zT4HbR8O8SnDsR7X7i7AqFk2kr732GmfOnMnxVrNmTfz8/Lh5M3Mn51u3buHr65vn8vz9/QkMDOTChQvZbjNu3DiioqL0t+vXrxfo2MRDEUdhZXdI0P7MvpxXOVb2WYnTw244Pxz4gR8P/qh5uaLwy6pNpr+Hf44/5E3myl9w+meIC4NdYyFRasmsjUUbG/n4+ODj45Prdk2bNiUqKor9+/fTqJE6KPO///5LVFQUzZo1y3N5kZGRXL9+HX//7GeNcHZ2xtnZOc/PKXJwZjFsGASpybDzbWivfVJrWq4ps56axUtrXgLgtb9eo1qparQMbKl52aLwGrNxDD5uPrzX4j3zJM808fdg09D0+y2/BFdv85Uv8sQmrpFWq1aNTp06MXToUPbt28e+ffsYOnQoXbt2NWixW7VqVVauXAlAbGwsb731Fnv37uXq1ats376dbt264ePjwzPPPGOpQylaApqB/cMfJcdnw9XNZil2cL3BjG6iVusmpybTc2lPTkacNEvZovCZvm860/+dzgfbPmDgqoHmLXzHm+oY1gCB7aHWy+YtX+SJTSRSgMWLF1OrVi06dOhAhw4dqF27Nr/88ovBNufOnSMqKgoAe3t7Tpw4QY8ePahcuTIDBw6kcuXK7N27Fw8PD0scQtHjFaz+gk6zaYhZqngBvmj/BR0qqiO+RD6I5Mmfn+Tc7XNmKVsUHjMPzDS41t4qsJX5Cr/yF5x8OAC+kwd0mCuDL1gpmxmQwVJkQAYjKanw+5NwfZt6v9ZQ6DDbLEVHxUfR/pf2HAhVx+FtUrYJe17aY96qOWGz5h+Zr79EADCh1QQmtp5onsITomBBjfSz0faz1dbwokBkPlJh23R20HEeOLqr90/MgaubzFK0l4sXG17cQB3fOgQXD+bXnr9KEhV58uuJXxmyZoj+/tjmY5nQaoL5Atg+Rqp0bYgkUqG9TFW8L5utireka0k299/MzsE7CS4RbJYyhW1bcHQBL654EeXhhPX/a/w/JrebbL4fYVKla3MkkQrzqDMMyrdVl2Ouw463zFZ0KfdSlPUsa7AuPjmey3cvmy0GYRt+PPgjg1cP1ifR4Q2GM63jNPPWZKQkgsvDlrmtvgbP8uYrWxSIJFJhHjo79Zd1WhXvyZ/Sp4Iys8SURJ5d9ixN5zXlxM0TFolBWJ/45Him7puqv/9GozeY8dQM818OqNQDBp2C5p9Ila6NkEQqzCetite7OrywF4pXtEgYE7ZNYP2F9UTERdBifgs2XtxokTiEdXFxcGHLgC0EFw9mbPOxTO803XLX1N19ocn7UqVrI6TVbi6k1a6JKanqEGcOlhv04u6Du3Ra3In9N/YDYKez48v2XzK6yWhpjCS4++AuxV2Km/e9EBsKbr4yEL1GpNWuKFx0dhZNogAlXEvwd/+/9YONpyqpvLnpTQavHkx8crxFYxPmc+72OZ5e8jTRjzR8K+FawrxJ9EEkLGkBq3uYrRGeMC1JpMKyUpJgy+vqYNxm5OHswfLey/mw5Yf6dQuPLaT1gtaExYSZNRZhfn9d+IvGcxuz+txq+q3oR4ql5vZMSYI/e0PUZbi8Dv4ebpk4hFEkkQrLSUmEFZ3g6Pew9TX4b6dZi7fT2fFRm49Y+txSXB3UicD/vfEvDec05MCNA2aNRZiHoih8tecruv7WlagEdRS0a/eucefBHcsEtONNCNmqLruVhhZTLBOHMIokUmE59k5Qqq66nJoMa56FqKtmD6N3jd7sfmk35TzVKfNCY0KZc3iO2eMQ2opPjmfgqoG8vfltUpVUAHpW68meIXso5V7K/AEdnwtHvlOX7Ryh+wrwlGkbbZEkUmFZLadAUEd1+cFt9TpRYqzZw6jnX48DQw/QvFxzmpRtwredvzV7DEI7R8KO0HhuY345nj4+94RWE/i91+8Ucypm/oD++we2jEy//+QsKNPc/HEIk5BWu7mQVrtmEH8Xfm0Mdx/OE/vYs9BtmdowycwSkhOISYzBx81wer+r964SVDzI7PEI4ySmJPLpzk/57J/PSE5NBsDN0Y2fn/6ZZ6s/a5mgokNgUUN4cEu9X/9/0Ga6ZWIpIqTVrij8XEpAjzXg9PANfmE57P3YIqE4OzhnSqLHwo9R+bvKDF0zlKj4KIvEJQpm06VNfLTzI30SreNbh71D9louiSbFwaoe6Um0/JPQ6ivLxCJMRhKpsA7eVaHrEuBht4O9E+H8H5aMCICklCQGrx5MUmoSc4/MpebMmjKAgw3pWrkrz1V/Dgc7Bya0msD+ofup7VvbcgHt+xRuHVWXi1eErkvBzsFy8QiTkEQqrEdwZ2j5Rfr99f3M3pL3UQ52DgxvOFx/He2/6P/otLiTnJ1aqSt3r2RaN6PLDPa/vJ+JrSfiZO9kgagyaPIBVO6tDkb/9BpwLWnZeIRJSCIV1qXhm1BjkLrs1xhK17NoODqdjlcavMLJESd5ssKT+vVpZ6e/nvhV3wJUWM6dB3d4e9PbVP6+Mn+cNqzJKOVeinr+ln0f6Tm6qTUv/Q6oQ2WKQkEaG+VCGhtZQGoyHPgS6r+RPsi9FVAUhTmH5/DmpjeJzdCyuI5vHSa3m0ynSp1kiEEzu590n2/2fcOU3VP0/UJLuZXi1MhTlunS8ihFURvTyZmnRUljI1H02DlA43GZk6iFf/NlPDvtVKmTfv2xm8eYsls60ptTUkoSPx78kUrfVuK9re/pk6izvTMjHx+Jl4uXhSN8aM9E+KWexWY6EuYhiVTYhvsRsLQVhO6zdCQEFg/kr35/sbn/Zhr4NwDg8yc/l7NRM0hVUll2ahk1ZtRg+LrhhMWqwzna6ex4qe5LXHj9gnVcC1UU2D0B9n0EMSHqe1fG0S20pGo3F1K1awXiwmFZG7hzFhyLQc91ULalpaMC1C/2Pdf38ET5JwzWb7i4gWWnljG+1Xjpf2oiSSlJtJjfgn9v/Guw/pmqz/BJ20+oXspKrjkqCux6Fw5kaDjX5hv1UoWwCKnaFcLJA4qVUZeTYmF5J7j2t2VjeshOZ5cpiaYqqbz797vMPzqfit9WpMeSHmy8uFEaJRnJ0d6RmqVr6u+3CmzF3iF7WdFnhXUl0W2jHkmi0yWJFnKSSIX1c3SHp9dCcBf1fvIDWNkVLq+3bFzZOHf7HFfvXQXUpLrm3Bo6Le5E5e8q8/Wery03QLoNOX7zOCPXjcz0v5rYeiJNyjbhr35/sW3gNpqUbWKhCLOgpKqztxzJMLzkk7PUkYtEoSZVu7mQql0rkpwA656Hi6vU+3aO0GEu1Bhg0bCycufBHX7Y/wM/HvqRGzE3DB5zcXDh+ZrP8+rjr9IwoKGFIrQ+CckJLD+znBkHZrD7+m4Avu7wNWOajrFwZHmQ9AA2vgTnlqj3dXbQ8SeoMdCycQlA++9xSaS5kERqZVKS4K/+cG5p+rqGb0GLz8HO3nJxZSM5NZm159Yy4+AM/r5sWB1tr7Mn9M1QSruXtlB0lpeSmsK/N/5l5ZmV/Hz8ZyLiIgwer+dXj8PDDlsoujxKTYbfmkP4fvW+zh66LIKqz1s2LqGn9fe4jE0lbIu9I3RZDC4l4dhMdd3BryDylDpSjJUNt+Zg58Az1Z7hmWrPcO72OWYdnMX8o/OJSojimWrPZEqii48v5jHvx2gY0BA7Cwzaby77b+xn1sFZ/Hn+T27dv5Xp8RqlajDy8ZG8WPtFC0SXT3YOUPk5NZE6ukOXX6FSd0tHJczIur51hMgLO3t4cgb41IJtb6hnBKXqWF0SfVQVnypM6zSNT9p+wpKTS6jlW8vg8fjkeF758xXuJ93Hr5gf3Sp3o1vlbrSr0A43RzcLRa2Ni3cuMv/ofIN1DnYOPFvtWUY+PpIW5VvYVneihm/Bg0io1g9K1cp9e1GoSNVuLqRq18pd3w6nFkCHeVZZtZsf6y+s56lfn8q03tXBleblm9PAv4F6C2hAcPFgq000CckJnIw4yaGwQxwKPcS/N/7l4zYf061KN/02dx/cpdSXpXBxcKFjpY50r9ydpyo/lWnmHauUmgw3dkO5VpaOROSRXCO1MEmkNur2KXUsUytNNlm5ff82q8+uZs35NWy+tJkHyQ+y3E6Hjqh3o/Bw9tCvi0uMw83RzezJ9dGkeTDsICduniApNclguyH1hjC3+1yDdfv+20ddv7q4OLiYM2TjxN+FP5+HkL+h518Q1MHSEYk8kGukQuRX6D5Y1gqqPA/tfwQb+aL2cfNhSP0hDKk/hPtJ99lyeQtrzq1h/cX1hMaE6rer4lPFIIkCjFw/klVnV1HGowwBHgH4e/jjX8xfXU776+FPGY8yuDq65hqLoihEPogkLCaMsNgwwmLCuHX/Fm81e8tgu77L+7Ly7Mocn0uHLlPLZcC6uq7kReRZWN09fQL69S/C0CtWNR60sAxJpKJwSYyFNT0hJRFO/wx3z0H3FVAswNKR5YuboxvdqnTTV4eGxoRyMPQgh0IP4emc+Rf1wdCDRCdEE50QzZnbZ7J93veeeI9P232qvx8WE0aV76vgZO9EcmoyyanJJKUmkZSShELmyqoRDUfg7pSeOOr51TNIpDp0VPWpSoOABjT0b0iDgAbU9aurn4bOZl1eD+v6QuLDYf5cfaD7H5JEBSCJVBQ2TsXU4dg2DILk+xD2LyysBW2/g6p9baqqN6MAjwC6V+lO9yqZW4OmKqlUKlmJhOQEQmNCs60SBvD38De4n5CSQExiTJ7jCIsNo1LJSvr7bYLb8OKdFwtX0swoMRZ2joVjM9LXlaoNPVaDV5DFwhLWRRKpKHyq9IISj8GqHuqA4fF31EnCz/8OT84Edz9LR2hSdjo7Vj+/GlCrZKMTogmLDSM0JpSwmId/Y9Uq2tq+tQ321aGjmk81ElMScbBzwNHeEQc7BxzsHPB29c5UNfxod50nyj+RaYjEQiNkmzrIQvTV9HWPPQudFqg/2IR4SBob5UIaG9mw+7dh62uGgze4lLT5s1NhBsd+VIf7S+Pgpg76Ue9VddQiYVNk0HohCsrNB7ougW5/gOvDSZ7Tzk73jLdsbMK6BXcBp4dfuGVbwsDjUP91SaIiS1K1Kwq/ys9C2VbpZ6f2zlDNBkbMEZbjWQ7afQ/x9+QsVORKEqkoGtLOTiv3gge3oWQVw8cVRap6i6qQbbB3ojrEpLNX+vrq/S0WkrAt8jNLFC2Vn4U6wwzXJT2AJS3gxDx11BpRNNyPgL9HwO9t4b+dsP1NS0ckbJQkUiH2jIfQ3bDpZVhYGy6sUs9QReGUGAN7JsLcinBsVvr6exfVqfqEyCep2hVFm5IKsemjBnHnDKx5BvybqK00ZTzVwiM5AY7/CPs+gQcZZpyRFrnCSNL9JRfS/aWI+O8f2DUWQvcYrg/qBC0mQ+m6FglLmEBqCpz9FXaPN+wTaucAtV6Bph8Wur7FwpAMWm9hkkiLEEWBy3/CrnHq/KYZVe0Lrb6GYv5Z7yusV9J9mFcJ4sLS11XtC80+ghKVst9PFBrSj1QIc9HpoGI3GHBMHb3Go3z6Y5fXgb2TxUITRnB0g6YP+w0HdYQXD8NTv0oSFSYjiVSIR9nZQ42B8NI5aD0NXLzh8bfB1dtwu+hrlolPZC0lCc7/AX90gKirho/VHAJ9dsKzG8C3nkXCE4WXVO3mQqp2BQnR6vU0R7f0dbGhMCcQfB+HuiOh8nM2M11boRNzA07MgeOz06tvqw+AzgstG5ewGjIfqRCWlsW0ZRyfo/Y5Ddur3raPVs966gwDr2Dzx1jUKApc3wZHZ8DFVaCkGD4efkCduUUGlxdmIIlUiIIo8Rj41ITbJ9X7D27DgSlw4Auo8JR6lhrUUbpTmFpCFJz6WZ3W7M5Zw8d09lCpB9QZCeXbykhVwmykajcXUrUrsqUocGO3+qV+/g9ITTJ83KsCNP8IqvWzTHyF0dWNsLyT4Tp3P6g1FGq/Ah5lLROXsGpStSuEtdLpoOwT6q31VHWIweM/Qsx19fGoy5Acb7hParJ6lipnqjlLjIVrm8DOCSp2TV8f2B6KV4R7l9SJCOqOhEpPS4tqYVFyRpoLOSMV+ZKarHaVOToDbh6AV/4zbKR0YaU6vmvFblChGwQ+afh4URbzH1xaC5fXQsgWSEkE/8bwwj7D7a5tUc9CfWpYJk5hc2RABguTRCoKLP4uuJQwXLdhMJxakH7fwQXKt4eK3dUzr6I0wo6iQMRRuLRGvUUczmIjHQwPLVr/F2FyUrUrhK16NImCWqXr4ArJD9T7yfHqGdjltbAZtQGTbwOo+gIEdTBruGYVeUaddSUuPOvHi5V5+OOiO7iUNG9sQuSTzVyo+fTTT2nWrBlubm4UL148T/soisLEiRMJCAjA1dWV1q1bc+rUqdx3FEIrHefByEh4eq3aQObRM63bJ+HUQrh9wnB90gM4/B2E7lWHvLN2ceFqFffej2Bldzg53/Bxj3IQd9NwXen60HSiOvLQK9fhyRkQ3EmufwqrZzNnpImJifTq1YumTZsyb968PO3zxRdfMHXqVBYsWEDlypX55JNPaN++PefOncPDw0PjiIXIhqOrWo1bsas6+8zNQ2rV5uX1cOuY2ifSt4HhPreOwbY31GWdHXhXV7fxqgDuAeoYwGl/3XzN1/Xjzjk16ceGQVwo3D4FEYcMZ9QBdcLsmoPT7zsVU2fYcSmunnVW6CotboXNsrlrpAsWLGDUqFHcu3cvx+0URSEgIIBRo0YxduxYABISEvD19WXKlCkMGzYsx/3TyDVSYVZJD+D2cfCpZdgI6cgPsPW13Pd3dIfXYwwT6Znf4O45cPdXH7dzVEdqsnNQl3U6QKc2lEpNVrvxpCaDkgzxd9KT5P1b0HO94XNvGwWHv8k9Lr/Hod/+vP4XhDApuUZaQFeuXCE8PJwOHdKvMzk7O9OqVSv27NmTbSJNSEggISF9ct/o6GjNYxVCz9FVban6qKCO0O4H9ez15iF1dprU5MzbuftnPhs9v0wd/ccU4u+Ca4Zrlu4Bmbdx9lKraX0bpN+KVzRN+UJYoUKbSMPD1UYMvr6+But9fX25di37wcYnT57MpEmTNI1NiHwrUclwtpLkeIg8DbE31GrUuDD15pxFA6eM04dlRWenVjHnRewNw0Ravo06Kba7PxQLAM8gKF5B+smKIsWiiXTixIm5Jq0DBw7QsGHDApehe+TXuaIomdZlNG7cOMaMGaO/Hx0dTbly5QpcvhCacHAB3/rqLTcd5qqzocSFQ0q8YfVt2lmtkpJe1ZtW7atzUMcZzngN1tnL8Ln9HldvQhRhFk2kr732Gs8//3yO2wQFBRXouf381NaQ4eHh+PunT8YcERGR6Sw1I2dnZ5ydnQtUphBWyaemehNCaMKiidTHxwcfHx9Nnjs4OBg/Pz82b95MvXrq/IOJiYns2LGDKVOmaFKmEEKIosdmLmSEhIRw9OhRQkJCSElJ4ejRoxw9epTY2Fj9NlWrVmXlypWAWqU7atQoPvvsM1auXMnJkycZNGgQbm5uvPDCC5Y6DCGEEIWMzTQ2Gj9+PAsXpk/Um3aWuW3bNlq3bg3AuXPniIqK0m/zzjvv8ODBA0aOHMndu3dp3LgxmzZtkj6kQgghTMbm+pGam/QjFUII26b197jNVO0KIYQQ1kgSqRBCCGEESaRCCCGEESSRCiGEEEaQRCqEEEIYQRKpEEIIYQRJpEIIIYQRJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQohhBBGkEQqhBBCGEESqRBCCGEESaRCCCGEESSRCiGEEEaQRCqEEEIYQRKpEEIIYQRJpEIIIYQRJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQohhBBGkEQqhBBCGEESqRBCCGEESaRCCCGEESSRCiGEEEaQRCqEEEIYQRKpEEIIYQRJpEIIIYQRJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQohhBBGkEQqhBBCGEESqRBCCGEESaRCCCGEESSRCiGEEEaQRCqEEEIYQRKpEEIIYQRJpEIIIYQRJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQohhBBGkEQqhBBCGEESqRBCCGEEm0mkn376Kc2aNcPNzY3ixYvnaZ9Bgwah0+kMbk2aNNE2UCGEEEWKzSTSxMREevXqxYgRI/K1X6dOnQgLC9Pf1q9fr1GEQgghiiIHSweQV5MmTQJgwYIF+drP2dkZPz8/DSISQgghbOiMtKC2b99O6dKlqVy5MkOHDiUiIsLSIQkhhChEbOaMtCA6d+5Mr169CAwM5MqVK3z44Ye0bduWQ4cO4ezsnOU+CQkJJCQk6O9HRUUBEB0dbZaYhRBCmFba97eiKNoUoFjQhAkTFCDH24EDBwz2mT9/vuLl5VWg8kJDQxVHR0dl+fLlRsUkN7nJTW5ys73bpUuXCpQ7cmPRM9LXXnuN559/PsdtgoKCTFaev78/gYGBXLhwIdttxo0bx5gxY/T37927R2BgICEhIXh5eZksFmsXHR1NuXLluH79Op6enpYOxyyK4jFD0TzuonjMUHSPOyoqivLly1OyZElNnt+iidTHxwcfHx+zlRcZGcn169fx9/fPdhtnZ+csq329vLyK1BsvjaenZ5E77qJ4zFA0j7soHjMU3eO2s9OmWZDNNDYKCQnh6NGjhISEkJKSwtGjRzl69CixsbH6bapWrcrKlSsBiI2N5a233mLv3r1cvXqV7du3061bN3x8fHjmmWcsdRhCCCEKGZtpbDR+/HgWLlyov1+vXj0Atm3bRuvWrQE4d+6cvnGQvb09J06c4Oeff+bevXv4+/vTpk0bli5dioeHh9njF0IIUTjZTCJdsGBBrn1IlQwtslxdXdm4caPR5To7OzNhwoRsW/kWVkXxuIviMUPRPO6ieMwgx63VcesURav2wEIIIUThZzPXSIUQQghrJIlUCCGEMIIkUiGEEMIIkkiFEEIII0gizUJRnPu0IMesKAoTJ04kICAAV1dXWrduzalTp7QN1MTu3r1L//798fLywsvLi/79+3Pv3r0c97HF13rGjBkEBwfj4uJCgwYN2LVrV47b79ixgwYNGuDi4kKFChWYNWuWmSI1nfwc8/bt2zO9pjqdjrNnz5oxYuPt3LmTbt26ERAQgE6nY9WqVbnuY+uvdX6PWYvXWhJpFori3KcFOeYvvviCqVOn8v3333PgwAH8/Pxo3749MTExGkZqWi+88AJHjx5lw4YNbNiwgaNHj9K/f/9c97Ol13rp0qWMGjWK999/nyNHjtCiRQs6d+5MSEhIlttfuXKFLl260KJFC44cOcJ7773HG2+8wfLly80cecHl95jTnDt3zuB1feyxx8wUsWnExcVRp04dvv/++zxtXxhe6/wecxqTvtaajOBbSORngPyBAwcqPXr00DQec8jrMaempip+fn7K559/rl8XHx+veHl5KbNmzdIwQtM5ffq0Aij79u3Tr9u7d68CKGfPns12P1t7rRs1aqQMHz7cYF3VqlWVd999N8vt33nnHaVq1aoG64YNG6Y0adJEsxhNLb/HvG3bNgVQ7t69a4bozANQVq5cmeM2heG1zigvx6zFay1npCZUlOY+vXLlCuHh4XTo0EG/ztnZmVatWrFnzx4LRpZ3e/fuxcvLi8aNG+vXNWnSBC8vr1yPwVZe68TERA4dOmTwOgF06NAh22Pcu3dvpu07duzIwYMHSUpK0ixWUynIMaepV68e/v7+tGvXjm3btmkZplWw9dfaGKZ8rSWRmkjnzp1ZvHgxW7du5euvv+bAgQO0bdvWYG7TwiQ8PBwAX19fg/W+vr76x6xdeHg4pUuXzrS+dOnSOR6DLb3Wt2/fJiUlJV+vU3h4eJbbJycnc/v2bc1iNZWCHLO/vz+zZ89m+fLlrFixgipVqtCuXTt27txpjpAtxtZf64LQ4rW2mSECjTVx4kQmTZqU4zYHDhygYcOGBXr+Pn366Jdr1qxJw4YNCQwMZN26dfTs2bNAz2ksrY8ZQKfTGdxXFCXTOnPL63FD5vgh92Owxtc6N/l9nbLaPqv11iw/x1ylShWqVKmiv9+0aVOuX7/OV199RcuWLTWN09IKw2udH1q81kUmkVrj3Kda0/KY/fz8APUXbcZp6SIiIjL9wjW3vB738ePHuXnzZqbHbt26la9jsIbXOjs+Pj7Y29tnOhPL6XXy8/PLcnsHBwe8vb01i9VUCnLMWWnSpAmLFi0ydXhWxdZfa1Mx9rUuMonUGuc+1ZqWxxwcHIyfnx+bN2/Wz8STmJjIjh07mDJliiZl5lVej7tp06ZERUWxf/9+GjVqBMC///5LVFQUzZo1y3N51vBaZ8fJyYkGDRqwefNmg+kDN2/eTI8ePbLcp2nTpqxdu9Zg3aZNm2jYsCGOjo6axmsKBTnmrBw5csQqX1NTsvXX2lSMfq1N1mypELl27Zpy5MgRZdKkSUqxYsWUI0eOKEeOHFFiYmL021SpUkVZsWKFoiiKEhMTo7z55pvKnj17lCtXrijbtm1TmjZtqpQpU0aJjo621GHkS36PWVEU5fPPP1e8vLyUFStWKCdOnFD69u2r+Pv728wxK4qidOrUSaldu7ayd+9eZe/evUqtWrWUrl27Gmxj66/1kiVLFEdHR2XevHnK6dOnlVGjRinu7u7K1atXFUVRlHfffVfp37+/fvvLly8rbm5uyujRo5XTp08r8+bNUxwdHZU//vjDUoeQb/k95mnTpikrV65Uzp8/r5w8eVJ59913FUBZvny5pQ6hQGJiYvSfXUCZOnWqcuTIEeXatWuKohTO1zq/x6zFay2JNAsDBw5UgEy3bdu26bcBlPnz5yuKoij3799XOnTooJQqVUpxdHRUypcvrwwcOFAJCQmxzAEUQH6PWVHULjATJkxQ/Pz8FGdnZ6Vly5bKiRMnzB+8ESIjI5V+/fopHh4eioeHh9KvX79MzeILw2v9ww8/KIGBgYqTk5NSv359ZceOHfrHBg4cqLRq1cpg++3btyv16tVTnJyclKCgIGXmzJlmjth4+TnmKVOmKBUrVlRcXFyUEiVKKE888YSybt06C0RtnLSuHY/eBg4cqChK4Xyt83vMWrzWMo2aEEIIYQTp/iKEEEIYQRKpEEIIYQRJpEIIIYQRJJEKIYQQRpBEKoQQQhhBEqkQQghhBEmkQgghhBEkkQpRBE2cOJG6detaOgwhCgVJpEJYkUGDBqHT6dDpdDg4OFC+fHlGjBjB3bt3zRrH1atX9XHodDpKlChBy5Yt2bFjh9HPrdPpWLVqlfFBCmElJJEKYWU6depEWFgYV69eZe7cuaxdu5aRI0daJJa///6bsLAwduzYgaenJ126dOHKlSsFeq7ExEQTRyeEdZBEKoSVcXZ2xs/Pj7Jly9KhQwf69OnDpk2bDLaZP38+1apVw8XFhapVqzJjxgyDx8eOHUvlypVxc3OjQoUKfPjhhyQlJeU7Fm9vb/z8/KhduzY//vgj9+/fZ9OmTURGRtK3b1/Kli2Lm5sbtWrV4rfffjPYt3Xr1rz22muMGTMGHx8f2rdvr5+275lnnkGn05l06kIhLKXITKMmhC26fPkyGzZsMJjSas6cOUyYMIHvv/+eevXqceTIEYYOHYq7uzsDBw4EwMPDgwULFhAQEMCJEycYOnQoHh4evPPOOwWOxc3NDYCkpCTi4+Np0KABY8eOxdPTk3Xr1tG/f38qVKhA48aN9fssXLiQESNGsHv3bhRFwdvbm9KlSzN//nw6deqEvb19geMRwmoYNeS9EMKkBg4cqNjb2yvu7u6Ki4uLfiaLqVOn6rcpV66c8uuvvxrs9/HHHytNmzbN9nm/+OILpUGDBvr7EyZMUOrUqZPt9leuXFEA5ciRI4qiKEpsbKwybNgwxd7eXjl+/HiW+3Tp0kV588039fdbtWql1K1bN9N2gLJy5cpsyxbC1sgZqRBWpk2bNsycOZP79+8zd+5czp8/z+uvvw7ArVu3uH79OkOGDGHo0KH6fZKTk/Hy8tLf/+OPP5g+fToXL14kNjaW5ORkPD098x1Ls2bNsLOz4/79+/j7+7NgwQJq1apFSkoKn3/+OUuXLuXGjRskJCSQkJCAu7u7wf4NGzYs4H9BCNshiVQIK+Pu7k6lSpUA+Pbbb2nTpg2TJk3i448/JjU1FVCrdzNWoQL6atJ9+/bx/PPPM2nSJDp27IiXlxdLlizh66+/zncsS5cupXr16hQvXhxvb2/9+q+//ppp06Yxffp0atWqhbu7O6NGjcrUoOjRxCpEYSSJVAgrN2HCBDp37syIESMICAigTJkyXL58mX79+mW5/e7duwkMDOT999/Xr7t27VqByi5XrhwVK1bMtH7Xrl306NGDF198EYDU1FQuXLhAtWrVcn1OR0dHUlJSChSPENZIWu0KYeVat25NjRo1+OyzzwB1MIXJkyfzzTffcP78eU6cOMH8+fOZOnUqAJUqVSIkJIQlS5Zw6dIlvv32W1auXGnSmCpVqsTmzZvZs2cPZ86cYdiwYYSHh+dp36CgILZs2UJ4eLjZ+8cKoQVJpELYgDFjxjBnzhyuX7/Oyy+/zNy5c/XXK1u1asWCBQsIDg4GoEePHowePZrXXnuNunXrsmfPHj788EOTxvPhhx9Sv359OnbsSOvWrfHz8+Ppp5/O075ff/01mzdvply5ctSrV8+kcQlhCTpFURRLByGEEELYKjkjFUIIIYwgiVQIIYQwgiRSIYQQwgiSSIUQQggjSCIVQgghjCCJVAghhDCCJFIhhBDCCJJIhRBCCCNIIhVCCCGMIIlUCCGEMIIkUiGEEMIIkkiFEEIII/wfZ/ogMtFRw9MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(real_part, imag_part)\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Real Part')\n",
    "ax.set_ylabel('Imaginary Part')\n",
    "\n",
    "# Label the caption\n",
    "plt.title('Eigenvalue at %d nodes and 32 dim latent state' % node_num)\n",
    "\n",
    "# Add the unit circle\n",
    "unit_circle = Circle((0, 0), radius=1, fill=False, linestyle='--', linewidth=2, color = 'darkorange')\n",
    "half_circle = Circle((0, 0), radius=0.8, fill=False, linestyle='--', linewidth=2, color = 'green')\n",
    "\n",
    "ax.add_artist(unit_circle)\n",
    "ax.add_artist(half_circle)\n",
    "\n",
    "\n",
    "# Set the axis limits to show the full circle\n",
    "ax.set_xlim([-1.5, 1.5])\n",
    "ax.set_ylim([-1.5, 1.5])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0907fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = eigenvectors\n",
    "U_inv = tf.linalg.inv(U)\n",
    "U_inv_static = np.zeros(tf.shape(U_inv))\n",
    "for i in range(len(eigenvalues)):\n",
    "    eig = eigenvalues[i]\n",
    "    if tf.abs(eig) > epsilon:\n",
    "        U_inv_static[i,:] = tf.abs(U_inv[i,:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62eabd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02329242+0.j 0.03142685+0.j 0.0200076 +0.j ... 0.14382964+0.j\n",
      "  0.01192444+0.j 0.03404916+0.j]\n",
      " [0.05202407+0.j 0.02592809+0.j 0.19715963+0.j ... 0.14043681+0.j\n",
      "  0.13705724+0.j 0.09682909+0.j]\n",
      " [0.0520242 +0.j 0.0259282 +0.j 0.19715962+0.j ... 0.14043705+0.j\n",
      "  0.13705724+0.j 0.09682904+0.j]\n",
      " ...\n",
      " [0.        +0.j 0.        +0.j 0.        +0.j ... 0.        +0.j\n",
      "  0.        +0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.        +0.j ... 0.        +0.j\n",
      "  0.        +0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.        +0.j ... 0.        +0.j\n",
      "  0.        +0.j 0.        +0.j]], shape=(32, 32), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "# U = eigenvectors\n",
    "# U_inv = tf.linalg.inv(U)\n",
    "# U_inv_static = tf.zeros_like(U_inv)\n",
    "# for i in range(static_num):\n",
    "#     U_inv_static = tf.tensor_scatter_nd_update(U_inv_static,\n",
    "#                                                 indices=[[i]],\n",
    "#                                                 updates=[tf.abs(eigenvalues[i] * U_inv[i, :])])\n",
    "# print(U_inv_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ba65c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[-0.19731663,  0.01121156,  0.5505918 ,  0.7119236 , -0.43271193,\n",
       "         0.44589722,  0.06963895, -0.56004035, -0.43447953,  0.6557389 ,\n",
       "         0.45861855,  0.21972503, -0.21564569, -0.3520559 , -0.19093528,\n",
       "        -0.4065676 , -0.5687215 , -0.280802  ,  0.4333609 , -0.14292045,\n",
       "        -0.21930373,  0.05958398,  0.539366  , -0.28651774,  0.33915028,\n",
       "        -0.15365338, -0.41353112, -0.08747441, -0.08405096,  0.201535  ,\n",
       "         0.32425377, -0.5103728 ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_psi(x_train_scaled[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffce059",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_para_scaled = model_inv_psi(model_psi(x_train_scaled[200:201,:]) @ tf.math.real(tf.abs(U)) @ U_inv_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb2ff8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 466)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_para = scaler.inverse_transform(static_para_scaled)\n",
    "np.shape(static_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5058cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_num = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37e137a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 16)\n",
      "(16,)\n",
      "(16, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(26,), name=\"digits\")\n",
    "x = keras.layers.Dense(node_num, activation=\"relu\", kernel_initializer=\"uniform\",bias_initializer=\"uniform\")(inputs)\n",
    "outputs = keras.layers.Dense(2, name=\"predictions\",kernel_initializer=\"uniform\",bias_initializer=\"uniform\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "start_idx = 0\n",
    "for i, w in enumerate(model.trainable_weights):\n",
    "    w_shape = w.shape\n",
    "    print(w_shape)\n",
    "    w_size = tf.reduce_prod(w_shape)\n",
    "    end_idx = start_idx + w_size\n",
    "    w.assign(tf.cast(tf.reshape(static_para[0, start_idx:end_idx], w_shape), tf.float32))\n",
    "    start_idx = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaa61586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: float64\n",
      "Data type: float32\n",
      "[1. 0.]\n",
      "Original dimensions: (60000, 784)\n",
      "Reduced dimensions: (60000, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST data.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocessing: normalize pixel values to be between 0 and 1.\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Shuffle training data.\n",
    "shuffle_index = np.random.permutation(len(x_train))\n",
    "x_train, y_train = x_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "# Convert target labels to binary classification (digit < 5 or digit >= 5).\n",
    "y_train = (y_train < 5)\n",
    "y_test = (y_test < 5)\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Track the data type of x_train.\n",
    "dataType = x_train.dtype\n",
    "print(f\"Data type: {dataType}\")\n",
    "\n",
    "# Track the data type of y_test.\n",
    "labelType = y_test.dtype\n",
    "print(f\"Data type: {labelType}\")\n",
    "\n",
    "# Print the one-hot encoded label for the first training example.\n",
    "print(y_train[0])\n",
    "\n",
    "# Instantiate the training dataset.\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "# Perform PCA to reduce dimensionality of x_train.\n",
    "pca = PCA(n_components=0.7)  # retain 70% of variance\n",
    "x_train_reduced = pca.fit_transform(x_train.reshape(x_train.shape[0], -1))\n",
    "x_test_reduced = pca.transform(x_test.reshape(x_test.shape[0], -1))\n",
    "\n",
    "# Print the dimensions of the original and reduced datasets.\n",
    "print(\"Original dimensions:\", x_train.shape)\n",
    "print(\"Reduced dimensions:\", x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c910c2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 3.7719 - accuracy: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7718942165374756, 0.5250499844551086]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn,  metrics=[\"accuracy\"])        \n",
    "model.evaluate(x_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3f848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
